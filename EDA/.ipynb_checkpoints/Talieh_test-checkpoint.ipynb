{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cred_fp = '/ebs_volume/data/Credible/'\n",
    "ncred_fp = '/ebs_volume/data/notCredible/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles = pd.DataFrame(columns=('label',\n",
    "                                 'text',\n",
    "                                 'title',\n",
    "                                 'date',\n",
    "                                 'source',\n",
    "                                 'images',\n",
    "                                 'videos',\n",
    "                                 'url'))\n",
    "i = 0    \n",
    "for root, dirs, files in os.walk(cred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print curr_file\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    articles.loc[i] = [0,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"],data[\"images\"],data[\"videos\"],data[\"url\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "for root, dirs, files in os.walk(ncred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print curr_file\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    articles.loc[i] = [1,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"],data[\"images\"],data[\"videos\"],data[\"url\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th>count</th>\n",
       "      <td>1592</td>\n",
       "      <td>1592</td>\n",
       "      <td>1592</td>\n",
       "      <td>1592</td>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1449</td>\n",
       "      <td>1448</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td>Article 50</td>\n",
       "      <td>04-04-2017</td>\n",
       "      <td>the-washington-post</td>\n",
       "      <td>http://www.independent.co.uk/topic/article-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.0</th>\n",
       "      <th>count</th>\n",
       "      <td>4124</td>\n",
       "      <td>4124</td>\n",
       "      <td>4124</td>\n",
       "      <td>4124</td>\n",
       "      <td>4124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3248</td>\n",
       "      <td>3363</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>3329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td>John McCain Illegally Travels To Syria, Meets ...</td>\n",
       "      <td>02-25-2017</td>\n",
       "      <td>activistpost</td>\n",
       "      <td>http://www.activistpost.com/2017/02/huge-week-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>636</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text                                              title  \\\n",
       "label                                                                   \n",
       "0.0   count   1592                                               1592   \n",
       "      unique  1449                                               1448   \n",
       "      top                                                  Article 50   \n",
       "      freq      20                                                  7   \n",
       "1.0   count   4124                                               4124   \n",
       "      unique  3248                                               3363   \n",
       "      top           John McCain Illegally Travels To Syria, Meets ...   \n",
       "      freq      46                                                 11   \n",
       "\n",
       "                    date               source  \\\n",
       "label                                           \n",
       "0.0   count         1592                 1592   \n",
       "      unique          36                   12   \n",
       "      top     04-04-2017  the-washington-post   \n",
       "      freq            65                  180   \n",
       "1.0   count         4124                 4124   \n",
       "      unique          43                   14   \n",
       "      top     02-25-2017         activistpost   \n",
       "      freq           169                  636   \n",
       "\n",
       "                                                            url  \n",
       "label                                                            \n",
       "0.0   count                                                1592  \n",
       "      unique                                               1489  \n",
       "      top         http://www.independent.co.uk/topic/article-50  \n",
       "      freq                                                    7  \n",
       "1.0   count                                                4124  \n",
       "      unique                                               3329  \n",
       "      top     http://www.activistpost.com/2017/02/huge-week-...  \n",
       "      freq                                                    7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of credible articles in corpus: 1592\n"
     ]
    }
   ],
   "source": [
    "cred_articles = articles[articles[\"label\"]==0.0]\n",
    "num_cred_articles = len(cred_articles)\n",
    "print(\"Number of credible articles in corpus: {}\".format(num_cred_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncred_articles = articles[articles[\"label\"]==1.0].sample(n=num_cred_articles)\n",
    "even_articles = pd.concat([cred_articles, noncred_articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "caps = \"([A-Z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "even_articles['sentences']=even_articles['text'].apply(split_into_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['View Images An uncrewed Dragon capsule makes the journey to the International Space Station.', 'The human-ready version has yet to fly in space.', 'Photograph by NASA  In a surprising and somewhat secretive press briefing, Elon Musk announced today that his company SpaceX intends to fly two paying passengers to the moon by late 2018.', 'The pair reportedly approached SpaceX with the idea and have paid the company a “significant deposit”.', 'As envisioned, the mission would lift off from Pad 39A at NASA’s Kennedy Space Center in Cape Canaveral, Florida—the same launch pad from which the Apollo missions blasted off more than four decades ago, delivering astronauts into lunar orbit and onto the moon’s surface.', 'The SpaceX passengers wouldn’t walk on the moon, though; the trip would slingshot them around the moon before returning to Earth.', '“This presents an opportunity for humans to return to deep space for the first time in 45 years and they will travel faster and further into the Solar System than any before them,” SpaceX said in a statement.', 'WATCH: Tour the SpaceX Dragon Crew Capsule    With its anticipated launch date pegged to next year, the SpaceX plan is an audacious moonshot, contingent upon efficient technology development and reliable funding.', 'But there’s no doubt that sending humans back to the moon would be exciting, whenever and however it happens.', 'Cool.', 'So who’s going?', 'It’s still a mystery.', 'The lunar tourists are two private citizens whom Musk declined to identify.', 'But according to the Associated Press, they apparently know one another—which is good, because being stuffed in a space capsule with someone for a week would be difficult under the best of circumstances.', 'How will these private citizens get to the moon?', 'The plan for now is for the mystery pair to hitch a ride aboard a next-generation version of SpaceX’s Dragon capsule, which is already in service carrying un-piloted cargo missions to the International Space Station.', 'The crew-compatible Dragon 2 capsule, which will fly autonomously, is still in the design and testing phase.', 'SpaceX intends to test the Dragon 2 later this year and send humans to the International Space Station aboard it in mid-2018.', 'If all goes to plan, the moon mission could launch in late 2018.', 'After leaving Earth’s orbit, the Dragon 2 would loop around the moon and briefly venture into deeper space before returning home.', 'The SpaceX itinerary suggests the trip will last about a week and cover as much as 400,000 miles, giving new meaning to the concept of frequent flier miles.', 'However, given the company’s somewhat loose relationship with deadlines, some critics wonder whether a human Dragon mission will occur when Musk says it will.', 'There’s also the issue of getting the capsule into space.', 'To lift something as weighty as a crewed Dragon 2 capsule, SpaceX will need its Falcon Heavy rocket, an as-yet unproven vehicle that for years has repeatedly missed its scheduled debut dates.', 'Has SpaceX flown anything to the moon before?', 'Nope.', 'The company has been ferrying goods to and from the ISS since 2012, and Musk recently announced an ambitious strategy for sending people to Mars in the near future.', 'If SpaceX does indeed achieve its goal of ferrying people to the moon in late 2018, it will be the first time humans have visited the immediate lunar neighborhood since Apollo 17, which flew in 1972.', 'What sort of training will private passengers need to fly?', 'It’s unclear at this point, but one of the reasons Musk declined to identify the passengers is because they can’t fly until they’ve completed a series of health checkups and training regimens.', 'Astronauts preparing for missions aboard the International Space Station are in exceptionally good physical condition.', 'They undergo a litany of physical examinations and train for the challenges of microgravity using a variety of simulators, including submerged replicas of the space station.', 'What does NASA make of this development?', 'In an official statement, NASA says it “commends its industry partners for reaching higher,” and that burgeoning public-private collaboration will “free the agency to focus on developing the next-generation rocket, spacecraft and systems to go beyond the moon and sustain deep space exploration”.', 'Musk has said that he prioritizes collaboration with NASA, and that if the agency wishes to send its own astronauts to the moon aboard a Dragon 2 capsule, they could displace the private passengers on the capsule’s maiden moon voyage.', 'What could possibly go wrong?', 'The interpersonal and psychological challenges associated with deep space missions are also an active area of research, and let’s just say that it’s not usually acceptable to vote a disagreeable team member off the island once your spaceship is en route.']\n"
     ]
    }
   ],
   "source": [
    "print(even_articles['sentences'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def sent_analysis(in_string):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    counter=0\n",
    "    total_neg=0\n",
    "    total_pos=0\n",
    "    total_neu=0\n",
    "    total_compound=0\n",
    "    sent=[]\n",
    "    for sentence in in_string:\n",
    "        #print(sentence)\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        total_neg=total_neg+ss['neg']\n",
    "        total_pos=total_pos+ss['pos']\n",
    "        total_neu=total_neu+ss['neu']\n",
    "        total_compound=total_compound+ss['compound']\n",
    "        counter=counter+1\n",
    "        #for k in sorted(ss):\n",
    "            #  print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "        #print()\n",
    "    sent.append(total_neg)\n",
    "    sent.append(total_pos)\n",
    "    sent.append(total_neu)\n",
    "    # print (total_neg)\n",
    "    #print (total_pos)\n",
    "    #print (total_compound)\n",
    "    if counter==0:\n",
    "        avg_compound=0\n",
    "    else:\n",
    "        avg_compound=total_compound/(counter)\n",
    "\n",
    "    sent.append(avg_compound)\n",
    "\n",
    "    #print(avg_compound)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "even_articles['sent']=even_articles['sentences'].apply(sent_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (2547, 10)\n",
      "test data shape: (637, 10)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(even_articles, test_size = 0.2)\n",
    "print(\"train data shape:\", train.shape)\n",
    "print(\"test data shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3184, 3)\n",
      "(3184, 1)\n",
      "(3184, 3)\n"
     ]
    }
   ],
   "source": [
    "#even_articles['sent'].head(20)\n",
    "#print(even_articles['sent'][1])\n",
    "#print(even_articles['sent'][1][1])\n",
    "\n",
    "objs = pd.DataFrame(even_articles['sent'].tolist())\n",
    "#pd.concat(objs, axis=1).drop('sent', axis=1)\n",
    "#print(objs)\n",
    "#test=np.array(objs)\n",
    "#print(test)\n",
    "#test=even_articles['sent'].reshape((-1,1))\n",
    "objs=np.array(objs)\n",
    "print(objs.shape)\n",
    "test2=objs.reshape(3184,3)\n",
    "print(test.shape)\n",
    "print(test2.shape)\n",
    "#sent_df = objs.apply(lambda x: pd.Series(x.split(',')))\n",
    "#print(sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (2123, 3)\n",
      "train classification shape (2123,)\n",
      "train data shape: (2123, 3)\n",
      "train classification shape (2123,)\n",
      "train data shape: (2123, 3)\n",
      "train classification shape (2123,)\n",
      "train data shape: (2123, 3)\n",
      "train classification shape (2123,)\n",
      "train data shape: (2123, 3)\n",
      "train classification shape (2123,)\n",
      "Cross Validation Metrics\n",
      "Total articles classified: 2547\n",
      "Accuracy Score: 0.627\n",
      "F1 Score: 0.649\n",
      "Confusion matrix:\n",
      "[[600 435]\n",
      " [355 730]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "scores = []\n",
    "f_scores=[]\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_sent = train.iloc[train_indices]['sent'].values\n",
    "    \n",
    "    \n",
    "    train_objs = pd.DataFrame(train_sent.tolist())\n",
    "    train_objs=np.array(train_objs)\n",
    "    \n",
    "    train_y = train.iloc[train_indices]['label'].values\n",
    "    \n",
    "    \n",
    "    print(\"train data shape:\", train_objs.shape)\n",
    "    print(\"train classification shape\", train_y.shape)\n",
    "\n",
    "    test_sent = train.iloc[test_indices]['sent'].values\n",
    "    test_objs = pd.DataFrame(test_sent.tolist())\n",
    "    test_objs=np.array(test_objs)\n",
    "    test_y = train.iloc[test_indices]['label'].values\n",
    "    test_sent=np.array(test_sent)\n",
    "    clf = LogisticRegression().fit(train_objs, train_y)\n",
    "    #clf.fit(train_sent, train_y)\n",
    "    predictions = clf.predict(test_objs)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    f_score = f1_score(test_y, predictions)\n",
    "    score = accuracy_score(test_y, predictions)\n",
    "    scores.append(score)\n",
    "    f_scores.append(f_score)\n",
    "    \n",
    "print ('Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train))\n",
    "print('Accuracy Score:', round(sum(scores)/len(scores),3))\n",
    "print('F1 Score:', round(sum(f_scores)/len(f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-68c6c31371d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mk_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "scores = []\n",
    "f_scores=[]\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_sent = train.iloc[train_indices]['sent'].values\n",
    "    \n",
    "    \n",
    "    train_objs = pd.DataFrame(train_sent.tolist())\n",
    "    train_objs=np.array(train_objs)\n",
    "    \n",
    "    train_y = train.iloc[train_indices]['label'].values\n",
    "    \n",
    "    \n",
    "    print(\"train data shape:\", train_objs.shape)\n",
    "    print(\"train classification shape\", train_y.shape)\n",
    "    dtrain=xgb.DMatrix(train_objs, label=train_y)\n",
    "    test_sent = train.iloc[test_indices]['sent'].values\n",
    "    test_objs = pd.DataFrame(test_sent.tolist())\n",
    "    test_objs=np.array(test_objs)\n",
    "    test_y = train.iloc[test_indices]['label'].values\n",
    "    test_sent=np.array(test_sent)\n",
    "    dtest=xgb.DMatrix(test_objs, label=test_y)\n",
    "    \n",
    "    params={'eval_metric':['auc','error'],'eta': 0.1, 'seed': 0, 'objective':'binary:logistic', 'max_depth':6 }\n",
    "    num_rounds=100\n",
    "    bst=xgb.train(params, dtrain, num_rounds,evallist)\n",
    "    predictions=bst.predict(dtest)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    f_score = f1_score(test_y, predictions)\n",
    "    score = accuracy_score(test_y, predictions)\n",
    "    scores.append(score)\n",
    "    f_scores.append(f_score)\n",
    "    \n",
    "print ('Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train))\n",
    "print('Accuracy Score:', round(sum(scores)/len(scores),3))\n",
    "print('F1 Score:', round(sum(f_scores)/len(f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
