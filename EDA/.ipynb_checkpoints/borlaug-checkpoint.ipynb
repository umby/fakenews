{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cred_fp = '/ebs_volume/data/Credible/'\n",
    "ncred_fp = '/ebs_volume/data/notCredible/'\n",
    "\n",
    "articles = pd.DataFrame(columns=('label',\n",
    "                                 'text',\n",
    "                                 'title',\n",
    "                                 'date',\n",
    "                                 'source'))\n",
    "i = 0    \n",
    "for root, dirs, files in os.walk(cred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print curr_file\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    if data[\"source\"] == \"new-york-times\":\n",
    "                        articles.loc[i] = [0,data[\"text\"],data[\"title\"],data[\"date\"],\"the-new-york-times\"]\n",
    "                    else:                        \n",
    "                        articles.loc[i] = [0,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "for root, dirs, files in os.walk(ncred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print curr_file\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    articles.loc[i] = [1,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th>count</th>\n",
       "      <td>2086</td>\n",
       "      <td>2086</td>\n",
       "      <td>2086</td>\n",
       "      <td>2086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>1899</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>04-05-2017</td>\n",
       "      <td>the-new-york-times</td>\n",
       "      <td></td>\n",
       "      <td>Article 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>67</td>\n",
       "      <td>221</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.0</th>\n",
       "      <th>count</th>\n",
       "      <td>4648</td>\n",
       "      <td>4648</td>\n",
       "      <td>4648</td>\n",
       "      <td>4648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>3758</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>02-25-2017</td>\n",
       "      <td>activistpost</td>\n",
       "      <td></td>\n",
       "      <td>John McCain Illegally Travels To Syria, Meets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>169</td>\n",
       "      <td>695</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date              source  text  \\\n",
       "label                                                \n",
       "0.0   count         2086                2086  2086   \n",
       "      unique          44                  11  1899   \n",
       "      top     04-05-2017  the-new-york-times         \n",
       "      freq            67                 221    22   \n",
       "1.0   count         4648                4648  4648   \n",
       "      unique          51                  14  3758   \n",
       "      top     02-25-2017        activistpost         \n",
       "      freq           169                 695    46   \n",
       "\n",
       "                                                          title  \n",
       "label                                                            \n",
       "0.0   count                                                2086  \n",
       "      unique                                               1898  \n",
       "      top                                            Article 50  \n",
       "      freq                                                    9  \n",
       "1.0   count                                                4648  \n",
       "      unique                                               3873  \n",
       "      top     John McCain Illegally Travels To Syria, Meets ...  \n",
       "      freq                                                   11  "
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6734\n",
      "5656\n"
     ]
    }
   ],
   "source": [
    "#Remove duplicate articles\n",
    "print(len(articles))\n",
    "unique_articles = articles.drop_duplicates(subset = 'text')\n",
    "print(len(unique_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5656\n",
      "5521\n"
     ]
    }
   ],
   "source": [
    "#Remove really short articles (<=200 chars)\n",
    "print(len(unique_articles))\n",
    "unique_articles = unique_articles[unique_articles[\"text\"].str.len()>200]\n",
    "print(len(unique_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ItMakesSenseBlog': 152,\n",
       "         'activistpost': 362,\n",
       "         'bbc-news': 206,\n",
       "         'bostonglobe': 111,\n",
       "         'darkmoon': 14,\n",
       "         'dcclothesline': 432,\n",
       "         'empirenews': 13,\n",
       "         'gopthedailydose': 546,\n",
       "         'independent': 215,\n",
       "         'infostormer': 152,\n",
       "         'latimes': 151,\n",
       "         'national-geographic': 171,\n",
       "         'nature': 20,\n",
       "         'reuters': 211,\n",
       "         'rickwells': 352,\n",
       "         'success-street': 299,\n",
       "         'the-new-york-times': 151,\n",
       "         'the-wall-street-journal': 215,\n",
       "         'the-washington-post': 218,\n",
       "         'usa-today': 218,\n",
       "         'usanewsflash': 494,\n",
       "         'usapoliticsnow': 428,\n",
       "         'usasupreme': 323,\n",
       "         'usfanzone': 67})"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(unique_articles[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of credible articles: 1013\n",
      "Number of non-credible articles: 3388\n"
     ]
    }
   ],
   "source": [
    "#cred_articles = unique_articles[unique_articles[\"label\"]==0.0]\n",
    "cred_articles = unique_articles[unique_articles[\"source\"].isin([\"new-york-times\",\"the-new-york-times\",\"reuters\",\"the-wall-street-journal\",\"the-washington-post\",\"usa-today\"])]\n",
    "num_cred_articles = len(cred_articles)\n",
    "print(\"Number of credible articles: {}\".format(num_cred_articles))\n",
    "#noncred_articles = unique_articles[unique_articles[\"label\"]==1.0]\n",
    "noncred_articles = unique_articles[unique_articles[\"source\"].isin([\"activistpost\",\"dcclothesline\",\"gopthedailydose\",\"infostormer\",\"rickwells\",\"success-street\",\"usanewsflash\",\"usapoliticsnow\",\"usasupreme\"])]\n",
    "print(\"Number of non-credible articles: {}\".format(len(noncred_articles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we desire an even number of credible/non-credible articles in our training set, we will need to downsample our non-credible set. We can sample in a way such that the number of credible and non-credible articles are equal for each day that we've been collecting data. This eliminates the possibility of a temporal bias appearing in our training set by chance occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cred_articles = cred_articles[~cred_articles[\"date\"].isin(list(set(cred_articles[\"date\"]) - set(noncred_articles[\"date\"])))]\n",
    "\n",
    "date_cnts = Counter(cred_articles[\"date\"])\n",
    "noncred_even = pd.DataFrame(columns=('label','text','title','date','source'))\n",
    "\n",
    "for date in date_cnts:\n",
    "    noncred_even = pd.concat([noncred_even, noncred_articles[noncred_articles[\"date\"]==date].sample(n=date_cnts[date])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test on 1930 articles\n"
     ]
    }
   ],
   "source": [
    "even_articles = pd.concat([cred_articles, noncred_even])\n",
    "print(\"Train/Test on {} articles\".format(len(even_articles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the-washington-post': 208, 'usa-today': 208, 'the-wall-street-journal': 205, 'reuters': 201, 'usanewsflash': 154, 'gopthedailydose': 153, 'the-new-york-times': 143, 'usapoliticsnow': 125, 'dcclothesline': 113, 'rickwells': 103, 'usasupreme': 96, 'activistpost': 96, 'success-street': 93, 'infostormer': 32})\n"
     ]
    }
   ],
   "source": [
    "source_counts = Counter(even_articles[\"source\"])\n",
    "print(source_counts)\n",
    "\n",
    "# plt.bar(range(len(source_counts)), source_counts.values(), align='center')\n",
    "# plt.xticks(range(len(source_counts)), source_counts.keys())\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 83469\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for text in even_articles[\"text\"]:\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        vocab.append(word.lower())\n",
    "print(\"Size of Vocabulary: {}\".format(len(set(vocab))))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Content-Based Classifier\n",
    "\n",
    "### 2.0.1) MNB on Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435    Wilbur Ross stands after being sworn in as Sec...\n",
       "436    Samsung Group chief, Jay Y. Lee arrives at the...\n",
       "437    A refugee walks along railway tracks from the ...\n",
       "438    Handout photo provided to Reuters on February ...\n",
       "439    U.S. President Donald Trump addresses Joint Se...\n",
       "440    U.S. President Donald Trump looks up while att...\n",
       "441    U.S. President Donald Trump attends a meeting ...\n",
       "442    Injured people are assisted after an incident ...\n",
       "443    WASHINGTON The Republican chairman of the U.S....\n",
       "444    MILWAUKEE A police officer and three other peo...\n",
       "445    A Texas law that requires voters to show ident...\n",
       "446    FILE PHOTO -- Chief Executive Officer of Unite...\n",
       "447    WASHINGTON The United States has made slight a...\n",
       "448    REFILE -- CORRECTING TYPO -- A student who was...\n",
       "449    A view of Alabama State Capital, where Alabama...\n",
       "450    U.S. Navy guided-missile destroyer USS Porter ...\n",
       "451    FILE PHOTOS: A combination of file photos show...\n",
       "452    FILE PHOTO - A U.S. F18 fighter jet lands on t...\n",
       "453    U.S. Ambassador to the United Nations Nikki Ha...\n",
       "454    PALM BEACH, Fla./WASHINGTON Top White House ai...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_articles[\"text\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MNB] -- Cross Validation Metrics\n",
      "Total articles classified: 1930\n",
      "Accuracy Score: 0.923\n",
      "F1 Score: 0.922\n",
      "Confusion matrix:\n",
      "[[897  68]\n",
      " [ 81 884]]\n",
      "\n",
      "[SVM] -- Cross Validation Metrics\n",
      "Total articles classified: 1930\n",
      "Accuracy Score: 0.953\n",
      "F1 Score: 0.953\n",
      "Confusion matrix:\n",
      "[[929  36]\n",
      " [ 54 911]]\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', ngram_range=(1,1), min_df=0)\n",
    "tfidf = TfidfTransformer()\n",
    "    \n",
    "#Perform cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "mnb_scores = []\n",
    "svm_scores = []\n",
    "mnb_f_scores=[]\n",
    "svm_f_scores=[]\n",
    "mnb_confusion = np.array([[0, 0], [0, 0]])\n",
    "svm_confusion = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_text = even_articles.iloc[train_index]['text'].values\n",
    "    train_counts = count_vect.fit_transform(train_text)\n",
    "    train_tfidf = tfidf.fit_transform(train_counts)\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "    \n",
    "    test_text = even_articles.iloc[test_index]['text'].values\n",
    "    test_counts = count_vect.transform(test_text)\n",
    "    test_tfidf = tfidf.transform(test_counts)\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "       \n",
    "    #MNB CLASSIFIER\n",
    "    mnb_clf = MultinomialNB().fit(train_tfidf, train_y)\n",
    "    mnb_predictions = mnb_clf.predict(test_tfidf)\n",
    "\n",
    "    mnb_confusion += confusion_matrix(test_y, mnb_predictions)\n",
    "    mnb_f_score = f1_score(test_y, mnb_predictions)\n",
    "    mnb_score = accuracy_score(test_y, mnb_predictions)\n",
    "    mnb_scores.append(mnb_score)\n",
    "    mnb_f_scores.append(mnb_f_score)\n",
    "    \n",
    "    #SVM CLASSIFIER\n",
    "    svm_clf = SVC(kernel=\"linear\").fit(train_tfidf, train_y)\n",
    "    svm_predictions = svm_clf.predict(test_tfidf)\n",
    "\n",
    "    svm_confusion += confusion_matrix(test_y, svm_predictions)\n",
    "    svm_f_score = f1_score(test_y, svm_predictions)\n",
    "    svm_score = accuracy_score(test_y, svm_predictions)\n",
    "    svm_scores.append(svm_score)\n",
    "    svm_f_scores.append(svm_f_score)\n",
    "\n",
    "print('[MNB] -- Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train_index) + len(test_index))\n",
    "print('Accuracy Score:', round(sum(mnb_scores)/len(mnb_scores),3))\n",
    "print('F1 Score:', round(sum(mnb_f_scores)/len(mnb_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(mnb_confusion)\n",
    "print()\n",
    "print('[SVM] -- Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train_index) + len(test_index))\n",
    "print('Accuracy Score:', round(sum(svm_scores)/len(svm_scores),3))\n",
    "print('F1 Score:', round(sum(svm_f_scores)/len(svm_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(svm_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t*PREDICTION = 0* \t\t\t*PREDICTION = 1*\n",
      "\t-5.412631593601138\tthe\t\t-5.432718657823109\tthe\n",
      "\t-6.14521640755403\tto\t\t-6.0837805396029205\tto\n",
      "\t-6.291272545617064\tof\t\t-6.206127414723071\tand\n",
      "\t-6.387079841852576\tand\t\t-6.2942655000975805\tof\n",
      "\t-6.461800972719331\tin\t\t-6.567436289237195\tthat\n",
      "\t-6.8569461337935\tthat\t\t-6.63820933336043\tin\n",
      "\t-6.954092340490268\ttrump\t\t-6.806882763508469\tis\n",
      "\t-6.966637753289567\tsaid\t\t-7.033062190392557\ttrump\n",
      "\t-7.022346832511469\ton\t\t-7.064768473902584\tfor\n",
      "\t-7.15281376701698\tfor\t\t-7.075807765224125\the\n",
      "\n",
      "\t  *Credible Features*\n",
      "\t advertisement       -2.708488\n",
      "       reuters       -2.314191\n",
      "          main       -2.228524\n",
      "          skip       -2.212761\n",
      "            mr       -1.985877\n",
      "         photo       -1.922435\n",
      "           inc       -1.644990\n",
      "         embed       -1.621755\n",
      "       editing       -1.498180\n",
      "           wsj       -1.405399\n",
      "\n",
      "\t*Non-Credible Features*\n",
      "\t   rickrwells        2.382595\n",
      "           www        2.152644\n",
      "         gowdy        1.950578\n",
      "           com        1.942618\n",
      "     rickwells        1.905116\n",
      "      facebook        1.820290\n",
      "    everywhere        1.812057\n",
      "            us        1.802723\n",
      "         wells        1.786570\n",
      "         https        1.770230\n"
     ]
    }
   ],
   "source": [
    "#Function returns log_prob_1 - log_prob_0 for each word in corpus & sorts by max (most predictive nc feats)/min (most predictive c feats)\n",
    "def show_most_predictive_feats(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    features = pd.DataFrame()\n",
    "    features[\"words\"] = feature_names\n",
    "    features[\"log_prob_0\"] = clf.feature_log_prob_[0]\n",
    "    features[\"log_prob_1\"] = clf.feature_log_prob_[1]\n",
    "    features[\"log_prob_diff\"] = features[\"log_prob_1\"] - features[\"log_prob_0\"]\n",
    "    features = features.drop('log_prob_0', 1).drop('log_prob_1', 1)\n",
    "    features_c_sort = features.sort_values(by=[\"log_prob_diff\"])\n",
    "    features_nc_sort = features.sort_values(by=[\"log_prob_diff\"], ascending=False)\n",
    "    print(\"\\t  *Credible Features*\")\n",
    "    print(\"\\t\", features_c_sort.head(n).to_string(index=False, header=False, col_space=15))\n",
    "    print()\n",
    "    print(\"\\t*Non-Credible Features*\")\n",
    "    print(\"\\t  \", features_nc_sort.head(n).to_string(index=False, header=False, col_space=15))\n",
    "    \n",
    "show_most_informative_feats(count_vect, mnb_clf, n=10)\n",
    "print()\n",
    "show_most_predictive_feats(count_vect, mnb_clf, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Filter Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove words with length <=2 from text\n",
    "def remove_shortwords(in_string):\n",
    "    out_string = in_string\n",
    "    out_words = out_string.split()\n",
    "    out_words = [word for word in out_words if len(word) > 2]\n",
    "    out_string = ' '.join(word for word in out_words)\n",
    "    return(out_string)\n",
    "\n",
    "#Remove words that shouldn't have the predictive power they are showing (regularization step only necessary for training)\n",
    "def remove_overfit_words(in_string, wordlist, sourcelist, phraselist):\n",
    "    out_string = in_string\n",
    "    for phrase in phraselist:\n",
    "        out_string = out_string.replace(phrase, '')\n",
    "    for source in sourcelist:\n",
    "        out_string = out_string.replace(source, '')\n",
    "    out_words = out_string.split()\n",
    "    out_words = [word for word in out_words if word not in wordlist]\n",
    "    out_string = ' '.join(word for word in out_words)\n",
    "    return(out_string)\n",
    "\n",
    "#Load in list of overfit words & phrases from training sources\n",
    "with open(\"text_redactions.txt\", \"r\") as infile:\n",
    "    wordlist = []\n",
    "    for line in infile:\n",
    "        wordlist.append(line.replace('\\n',''))\n",
    "\n",
    "#Generate sources list\n",
    "sources = list(set(even_articles['source']))\n",
    "sourcelist = [source.replace('-', ' ') for source in sources]\n",
    "sourcelist.append('rickrwells')\n",
    "sourcelist.append('rickwells')\n",
    "sourcelist.append('rick wells')\n",
    "sourcelist.append('wall street journal')\n",
    "sourcelist.append('gop the daily dose')\n",
    "sourcelist.append('new york times')\n",
    "sourcelist.append('washington post')\n",
    "sourcelist.append('activist post')\n",
    "\n",
    "#Generate indicative phrase list from training sources\n",
    "phraselist = [\"Share this:\",\n",
    "              \"by usapoliticsnow admin\",\n",
    "              \"Our Standards: The Thomson Reuters Trust Principles\",\n",
    "              \"Don't forget to follow the D.C. Clothesline on Facebook and Twitter. PLEASE help spread the word by sharing our articles on your favorite social networks.\",\n",
    "              \"Share With Your Friends On Facebook, Twitter, Everywhere\",\n",
    "              \"Thank you for reading and sharing my work –  Please look for me, Rick Wells, at http://www.facebook.com/RickRWells/ , http://www.gab.ai/RickRWells , https://plus.google.com/u/0/+RickwellsUs and on my website http://RickWells.US  – Please SUBSCRIBE in the right sidebar at RickWells.US – not dot com.  I’m also at Stop The Takeover, https://www.facebook.com/StopTheTakeover/ and please follow me on Twitter @RickRWells. Subscribe also on my YouTube Channel.\"\n",
    "              \"Like this Article? Share it!\",\n",
    "              \"Do you have information the public should know? Here are some ways you can securely send information and documents to Post journalists.\",\n",
    "              \"Share news tips with us confidentially\",\n",
    "             \"Share on Facebook\",\n",
    "             \"Tweet on Twitter\",\n",
    "             \"We encourage you to share and republish our reports, analyses, breaking news and videos (Click for details).\",\n",
    "             \"Next post\",\n",
    "             \"Previous post\"]\n",
    "\n",
    "even_articles['filtered_text'] = even_articles.apply(lambda x: remove_overfit_words(x['text'], wordlist=wordlist, sourcelist=sourcelist, phraselist=phraselist), axis=1)\n",
    "even_articles['filtered_text'] = even_articles['filtered_text'].apply(remove_shortwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435    Wilbur Ross stands after being sworn Secretary...\n",
       "436    Samsung Group chief, Jay Lee arrives the offic...\n",
       "437    refugee walks along railway tracks from the Un...\n",
       "438    Handout provided Reuters February 13, 2017, Hu...\n",
       "439    U.S. President Donald Trump addresses Joint Se...\n",
       "440    U.S. President Donald Trump looks while attend...\n",
       "441    U.S. President Donald Trump attends meeting wi...\n",
       "442    Injured people are assisted after incident Wes...\n",
       "443    WASHINGTON The Republican chairman the U.S. Ho...\n",
       "444    MILWAUKEE police officer and three other peopl...\n",
       "445    Texas law that requires voters show identifica...\n",
       "446    FILE PHOTO Chief Executive Officer United Airl...\n",
       "447    WASHINGTON The United States has made slight a...\n",
       "448    REFILE CORRECTING TYPO student who was evacuat...\n",
       "449    view Alabama State Capital, where Alabama Gove...\n",
       "450    U.S. Navy guided-missile destroyer USS Porter ...\n",
       "451    FILE PHOTOS: combination file photos show U.S....\n",
       "452    FILE PHOTO U.S. F18 fighter jet lands the deck...\n",
       "453    U.S. Ambassador the United Nations Nikki Haley...\n",
       "454    PALM BEACH, Fla./WASHINGTON Top White House ai...\n",
       "Name: filtered_text, dtype: object"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_articles['filtered_text'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 MNB & SVM classifier on \"filtered_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MNB] -- Cross Validation Metrics\n",
      "Total articles classified: 1930\n",
      "Accuracy Score: 0.906\n",
      "F1 Score: 0.901\n",
      "Confusion matrix:\n",
      "[[927  38]\n",
      " [143 822]]\n",
      "\n",
      "[SVM-Linear] -- Cross Validation Metrics\n",
      "Total articles classified: 1930\n",
      "Accuracy Score: 0.948\n",
      "F1 Score: 0.947\n",
      "Confusion matrix:\n",
      "[[923  42]\n",
      " [ 59 906]]\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', ngram_range=(1,1), min_df=0, lowercase=True, stop_words='english')\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "#Perform cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "mnb_scores = []\n",
    "svm_scores = []\n",
    "mnb_f_scores=[]\n",
    "svm_f_scores=[]\n",
    "mnb_confusion = np.array([[0, 0], [0, 0]])\n",
    "svm_confusion = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_text = even_articles.iloc[train_index]['filtered_text'].values\n",
    "    train_counts = count_vect.fit_transform(train_text)\n",
    "    train_tfidf = tfidf.fit_transform(train_counts)\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "\n",
    "    test_text = even_articles.iloc[test_index]['filtered_text'].values\n",
    "    test_counts = count_vect.transform(test_text)\n",
    "    test_tfidf = tfidf.transform(test_counts)\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "\n",
    "    #MNB CLASSIFIER\n",
    "    mnb_clf = MultinomialNB().fit(train_tfidf, train_y)\n",
    "    mnb_predictions = mnb_clf.predict(test_tfidf)\n",
    "\n",
    "    mnb_confusion += confusion_matrix(test_y, mnb_predictions)\n",
    "    mnb_f_score = f1_score(test_y, mnb_predictions)\n",
    "    mnb_score = accuracy_score(test_y, mnb_predictions)\n",
    "    mnb_scores.append(mnb_score)\n",
    "    mnb_f_scores.append(mnb_f_score)\n",
    "\n",
    "    #SVM CLASSIFIER - LINEAR KERNEL\n",
    "    svm_clf = SVC(kernel=\"linear\").fit(train_tfidf, train_y)\n",
    "    svm_predictions = svm_clf.predict(test_tfidf)\n",
    "\n",
    "    svm_confusion += confusion_matrix(test_y, svm_predictions)\n",
    "    svm_f_score = f1_score(test_y, svm_predictions)\n",
    "    svm_score = accuracy_score(test_y, svm_predictions)\n",
    "    svm_scores.append(svm_score)\n",
    "    svm_f_scores.append(svm_f_score)\n",
    "\n",
    "print('[MNB] -- Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train_index) + len(test_index))\n",
    "print('Accuracy Score:', round(sum(mnb_scores)/len(mnb_scores),3))\n",
    "print('F1 Score:', round(sum(mnb_f_scores)/len(mnb_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(mnb_confusion)\n",
    "print()\n",
    "print('[SVM-Linear] -- Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train_index) + len(test_index))\n",
    "print('Accuracy Score:', round(sum(svm_scores)/len(svm_scores),3))\n",
    "print('F1 Score:', round(sum(svm_f_scores)/len(svm_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(svm_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  *Credible Features*\n",
      "\t advertisement       -2.891066\n",
      "       reuters       -2.356618\n",
      "         photo       -2.345384\n",
      "          skip       -2.269950\n",
      "            mr       -2.019556\n",
      "         embed       -1.680976\n",
      "       editing       -1.580484\n",
      "     lawmakers       -1.504561\n",
      "         getty       -1.471699\n",
      "      continue       -1.465324\n",
      "       bentley       -1.439586\n",
      "        bannon       -1.434518\n",
      "    affordable       -1.434251\n",
      "          usat       -1.405379\n",
      "           gop       -1.388292\n",
      "      medicaid       -1.345687\n",
      "           wsj       -1.336679\n",
      "            ms       -1.325515\n",
      "            ly       -1.321291\n",
      "        budget       -1.294524\n",
      "    washington       -1.287409\n",
      "      mulvaney       -1.276039\n",
      "    republican       -1.237784\n",
      "           cbo       -1.229778\n",
      "        friday       -1.229068\n",
      "     tillerson       -1.223693\n",
      "          care       -1.222679\n",
      "      insurers       -1.221202\n",
      "        health       -1.219110\n",
      "     humankind       -1.218277\n",
      "     wednesday       -1.211277\n",
      "          uber       -1.185510\n",
      "     investors       -1.171309\n",
      "         berry       -1.169778\n",
      "       kushner       -1.154528\n",
      "       tuesday       -1.146897\n",
      "        spacex       -1.137035\n",
      "      overhaul       -1.131766\n",
      "           tax       -1.131748\n",
      "          file       -1.121529\n",
      "    occasional       -1.121205\n",
      "        caucus       -1.114079\n",
      " congressional       -1.102427\n",
      "        london       -1.098538\n",
      "          said       -1.097998\n",
      "        moscow       -1.096924\n",
      "      declined       -1.090894\n",
      "      proposal       -1.089607\n",
      "   transgender       -1.087914\n",
      "       invalid       -1.084898\n",
      "   newsletters       -1.083449\n",
      "   subscribing       -1.083449\n",
      "         story       -1.078964\n",
      "         robot       -1.070596\n",
      "     spokesman       -1.053963\n",
      "       capitol       -1.035221\n",
      "      clicking       -1.032667\n",
      "    parliament       -1.029562\n",
      "        senior       -1.020973\n",
      "   republicans       -1.019709\n",
      "      thursday       -1.017562\n",
      "          cuts       -1.017510\n",
      "         error       -1.016358\n",
      "   legislation       -1.014782\n",
      "           box       -1.009424\n",
      "           aca       -1.006187\n",
      "        yellen       -1.003074\n",
      "       adviser       -0.991216\n",
      "       roughly       -0.985683\n",
      "       updates       -0.983087\n",
      "       reading       -0.982244\n",
      "        verify       -0.982144\n",
      "           wis       -0.981486\n",
      "         trade       -0.981347\n",
      "         jason       -0.981100\n",
      "        monday       -0.973261\n",
      "       credits       -0.969705\n",
      "        rocket       -0.968327\n",
      "         aides       -0.965951\n",
      "    additional       -0.965753\n",
      "     officials       -0.964751\n",
      "          park       -0.959725\n",
      "        income       -0.951673\n",
      "     insurance       -0.949665\n",
      "        falcon       -0.939633\n",
      "      immunity       -0.938367\n",
      "       beijing       -0.937489\n",
      "         rates       -0.933895\n",
      "      jonathan       -0.933654\n",
      "         flynn       -0.928694\n",
      "      shooting       -0.928149\n",
      "      spending       -0.923291\n",
      "      advisers       -0.923254\n",
      "            ap       -0.919245\n",
      "      commerce       -0.917299\n",
      "     anonymity       -0.914845\n",
      "          ross       -0.913182\n",
      "           rex       -0.911348\n",
      "         visas       -0.896206\n",
      "       returns       -0.893122\n",
      "\n",
      "\t*Non-Credible Features*\n",
      "\t   rickrwells        2.608372\n",
      "            www        2.398637\n",
      "      rickwells        2.128337\n",
      "            com        2.079404\n",
      "          gowdy        1.908193\n",
      "          https        1.878573\n",
      "           rick        1.866851\n",
      "            gab        1.757905\n",
      "             ai        1.757589\n",
      "           mewe        1.740688\n",
      "stopthetakeover        1.662823\n",
      "       liberals        1.638667\n",
      "       facebook        1.582784\n",
      "          dobbs        1.573644\n",
      "       takeover        1.570096\n",
      "        sidebar        1.559759\n",
      "          wells        1.536932\n",
      "            dot        1.481321\n",
      "         shares        1.413028\n",
      "        hillary        1.405581\n",
      "        melania        1.359029\n",
      "        liberal        1.354477\n",
      "            vin        1.348006\n",
      "     mainstream        1.330177\n",
      "        klayman        1.319119\n",
      "           trey        1.289002\n",
      "         mccain        1.256718\n",
      "           isis        1.250755\n",
      "            god        1.248380\n",
      "           stop        1.241801\n",
      "        jeanine        1.234661\n",
      "        article        1.230902\n",
      "           asks        1.230389\n",
      "            doj        1.211280\n",
      "         stated        1.179654\n",
      "        illegal        1.157303\n",
      "        sharing        1.153792\n",
      "         pelosi        1.148739\n",
      "          truth        1.143786\n",
      "            pic        1.131274\n",
      "       illegals        1.128547\n",
      "         racist        1.127821\n",
      "     turbeville        1.127735\n",
      "         aliens        1.122146\n",
      "           word        1.120905\n",
      "          snoop        1.116113\n",
      "          islam        1.113925\n",
      "          notes        1.112871\n",
      "       michelle        1.107087\n",
      "          proud        1.105620\n",
      "          smart        1.102959\n",
      "         autism        1.098028\n",
      "     terrorists        1.084556\n",
      "         rickus        1.081801\n",
      "        clinton        1.079814\n",
      "         starve        1.071367\n",
      "        profile        1.066488\n",
      "          soros        1.057620\n",
      "      catherine        1.033951\n",
      "        hannity        1.031491\n",
      "        america        1.028796\n",
      "          knows        1.020237\n",
      "         armani        1.019960\n",
      "         sharia        1.005691\n",
      "       actually        1.004450\n",
      "     incredible        1.003111\n",
      "            cnn        0.987974\n",
      "      sanctuary        0.987636\n",
      "          spied        0.986722\n",
      "           http        0.984593\n",
      "        treason        0.980852\n",
      "          swamp        0.980103\n",
      "           fact        0.970395\n",
      "          needs        0.963206\n",
      "        finally        0.960318\n",
      "         spread        0.954508\n",
      "          saudi        0.949584\n",
      "     intellihub        0.945194\n",
      "        welfare        0.944330\n",
      "         follow        0.938332\n",
      "      unmasking        0.938278\n",
      "        patriot        0.937519\n",
      "         insane        0.930990\n",
      "           lady        0.929853\n",
      "          obama        0.927802\n",
      "       gingrich        0.927374\n",
      "        podesta        0.925718\n",
      "        stating        0.922370\n",
      "     journalist        0.921754\n",
      "      bombshell        0.917365\n",
      "          thugs        0.914670\n",
      "         thanks        0.912655\n",
      "         barron        0.909717\n",
      "         idiots        0.908718\n",
      "      globalist        0.908217\n",
      " geoengineering        0.907944\n",
      "         spying        0.906371\n",
      "      terrorist        0.906165\n",
      "     kaepernick        0.905382\n",
      "     propaganda        0.904879\n"
     ]
    }
   ],
   "source": [
    "show_most_predictive_feats(count_vect, mnb_clf, n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Perform stemming on words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perform stemming on words\n",
    "def stem_words(in_string):\n",
    "    snowball = nltk.stem.SnowballStemmer('english')\n",
    "    out_string = in_string\n",
    "    out_words = out_string.split()\n",
    "    out_words = [snowball.stem(word) for word in out_words]\n",
    "    out_string = ' '.join(word for word in out_words)\n",
    "    return(out_string)\n",
    "\n",
    "even_articles['stem_text'] = even_articles['filtered_text'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     view uncrew dragon capsul make journey intern ...\n",
       "1     watch impati eleph disobey railway rule young ...\n",
       "2     view advanc laser imag techniqu reveal new det...\n",
       "3     watch visitor badal wildlif park break rule ro...\n",
       "4     view particip slav vike festiv wolin poland te...\n",
       "5     nuclear bomb help fight eleph poach radioact c...\n",
       "6     view conserv clean surfac stone slab vener fin...\n",
       "7     ancient bug attract mate rare amber find tell ...\n",
       "8     sprawl million acr alaska nation wildlif refug...\n",
       "9     view rusti patch bumblebe bombus affini first ...\n",
       "10    giant deepsea octopus devour jellyfish—and kee...\n",
       "11    view new speci long confus close relat pristim...\n",
       "12    view secretari inspect newli print magazin chi...\n",
       "13    view white rhino graze ranch belong john hume ...\n",
       "14    long european settler establish commerci seal ...\n",
       "15    watch sea creatur shimmer disappear eye thousa...\n",
       "16    view phd candid hydrologist nathan reaver dive...\n",
       "17    watch miss man found dead insid python warn in...\n",
       "18    dark swallow daylight sudden chill seiz air su...\n",
       "19    view oklahoma saw 100 earthquak past seven day...\n",
       "Name: stem_text, dtype: object"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_articles['stem_text'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MNB] -- Cross Validation Metrics\n",
      "Total articles classified: 3774\n",
      "Accuracy Score: 0.912\n",
      "F1 Score: 0.91\n",
      "Confusion matrix:\n",
      "[[1762  125]\n",
      " [ 208 1679]]\n",
      "\n",
      "[SVM-Linear] -- Cross Validation Metrics\n",
      "Total articles classified: 3774\n",
      "Accuracy Score: 0.946\n",
      "F1 Score: 0.946\n",
      "Confusion matrix:\n",
      "[[1818   69]\n",
      " [ 133 1754]]\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', ngram_range=(1,1), min_df=0)\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "#Perform cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "mnb_scores = []\n",
    "svm_scores = []\n",
    "mnb_f_scores=[]\n",
    "svm_f_scores=[]\n",
    "mnb_confusion = np.array([[0, 0], [0, 0]])\n",
    "svm_confusion = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_text = even_articles.iloc[train_index]['stem_text'].values\n",
    "    train_counts = count_vect.fit_transform(train_text)\n",
    "    train_tfidf = tfidf.fit_transform(train_counts)\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "\n",
    "    test_text = even_articles.iloc[test_index]['stem_text'].values\n",
    "    test_counts = count_vect.transform(test_text)\n",
    "    test_tfidf = tfidf.transform(test_counts)\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "\n",
    "    #MNB CLASSIFIER\n",
    "    mnb_clf = MultinomialNB().fit(train_tfidf, train_y)\n",
    "    mnb_predictions = mnb_clf.predict(test_tfidf)\n",
    "\n",
    "    mnb_confusion += confusion_matrix(test_y, mnb_predictions)\n",
    "    mnb_f_score = f1_score(test_y, mnb_predictions)\n",
    "    mnb_score = accuracy_score(test_y, mnb_predictions)\n",
    "    mnb_scores.append(mnb_score)\n",
    "    mnb_f_scores.append(mnb_f_score)\n",
    "\n",
    "    #SVM CLASSIFIER - LINEAR KERNEL\n",
    "    svm_clf = SVC(kernel=\"linear\").fit(train_tfidf, train_y)\n",
    "    svm_predictions = svm_clf.predict(test_tfidf)\n",
    "\n",
    "    svm_confusion += confusion_matrix(test_y, svm_predictions)\n",
    "    svm_f_score = f1_score(test_y, svm_predictions)\n",
    "    svm_score = accuracy_score(test_y, svm_predictions)\n",
    "    svm_scores.append(svm_score)\n",
    "    svm_f_scores.append(svm_f_score)\n",
    "\n",
    "print('[MNB] -- Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train_index) + len(test_index))\n",
    "print('Accuracy Score:', round(sum(mnb_scores)/len(mnb_scores),3))\n",
    "print('F1 Score:', round(sum(mnb_f_scores)/len(mnb_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(mnb_confusion)\n",
    "print()\n",
    "print('[SVM-Linear] -- Cross Validation Metrics')\n",
    "print('Total articles classified:', len(train_index) + len(test_index))\n",
    "print('Accuracy Score:', round(sum(svm_scores)/len(svm_scores),3))\n",
    "print('F1 Score:', round(sum(svm_f_scores)/len(svm_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(svm_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t*PREDICTION = 0* \t\t\t*PREDICTION = 1*\n",
      "\t-6.581637671340962\tsaid\t\t-6.439528570241916\ttrump\n",
      "\t-6.674797391301648\ttrump\t\t-6.863770423825693\tpresid\n",
      "\t-7.20902222634294\thous\t\t-6.930768477843589\tobama\n",
      "\t-7.257771146422305\tpresid\t\t-7.416548171421603\tstate\n",
      "\t-7.410192441003275\twould\t\t-7.494673039701967\tsaid\n",
      "\t-7.502050106489097\trepublican\t\t-7.502306057801121\tshare\n",
      "\t-7.651935008041935\twhite\t\t-7.512699854649074\tpeopl\n",
      "\t-7.707707172027965\tpeopl\t\t-7.596972320112258\tone\n",
      "\t-7.76349289903372\tyear\t\t-7.6083777303958495\tit\n",
      "\t-7.773412442952562\tstate\t\t-7.640525240428502\tamerican\n",
      "\n",
      "\t  *Credible Features*\n",
      "\t brexit       -2.290469\n",
      "     westminst       -1.980606\n",
      "          skip       -1.948934\n",
      "       theresa       -1.875615\n",
      "           nhs       -1.796979\n",
      "        labour       -1.795167\n",
      "    parliament       -1.776802\n",
      "        dodger       -1.763648\n",
      "       britain       -1.728965\n",
      "         korea       -1.708322\n",
      "\n",
      "\t*Non-Credible Features*\n",
      "\t   everywher        2.356065\n",
      "      facebook        2.010376\n",
      "          soro        1.977389\n",
      "         gowdi        1.977388\n",
      "         liber        1.837266\n",
      "        mccain        1.791373\n",
      "        takeov        1.791326\n",
      "    mainstream        1.790763\n",
      "      catherin        1.756191\n",
      "       treason        1.720094\n"
     ]
    }
   ],
   "source": [
    "show_most_informative_feats(count_vect, mnb_clf, n=10)\n",
    "print()\n",
    "show_most_predictive_feats(count_vect, mnb_clf, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \"Tonal\" Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps = \"([A-Z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "even_articles['sentences'] = even_articles['text'].apply(split_into_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sent_analysis(text, uoa=\"sentences\"):\n",
    "    if uoa == \"sentences\":\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        counter=0\n",
    "        total_compound=0\n",
    "        for sentence in text:\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            total_compound = total_compound + ss['compound']\n",
    "            counter+=1\n",
    "\n",
    "        if counter==0:\n",
    "            avg_compound=0\n",
    "        else:\n",
    "            avg_compound = total_compound/counter\n",
    "\n",
    "        return(avg_compound)\n",
    "    \n",
    "    elif uoa == \"string\":\n",
    "        filtered_text = remove_cap_punc(text)\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        ss = sid.polarity_scores(filtered_text)\n",
    "        compound = ss['compound']\n",
    "        return(compound)\n",
    "    else:\n",
    "        print(\"uoa (unit of analysis) not recognized\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "even_articles['text_sentiment'] = even_articles['sentences'].apply(sent_analysis)\n",
    "even_articles['title_sentiment'] = even_articles.apply(lambda x: sent_analysis(x['title'], uoa=\"string\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credible avg. sentiment score on text: 0.014421412894685223 +/- 0.3383581262430465\n",
      "Non-Credible avg. sentiment score on text: -0.012806591275834053 +/- 0.3476911003027185\n",
      "\n",
      "Credible avg. sentiment score on title: -0.10641037911746429 +/- 0.7840593273817753\n",
      "Non-Credible avg. sentiment score on title: -0.17674953387197012 +/- 0.8061239586588453\n"
     ]
    }
   ],
   "source": [
    "print('Credible avg. sentiment score on text:', np.mean(even_articles['text_sentiment'][even_articles['label']==0]), '+/-', 2*np.std(even_articles['text_sentiment'][even_articles['label']==0]))\n",
    "print('Non-Credible avg. sentiment score on text:', np.mean(even_articles['text_sentiment'][even_articles['label']==1]), '+/-', 2*np.std(even_articles['text_sentiment'][even_articles['label']==1]))\n",
    "print()\n",
    "print('Credible avg. sentiment score on title:', np.mean(even_articles['title_sentiment'][even_articles['label']==0]), '+/-', 2*np.std(even_articles['title_sentiment'][even_articles['label']==0]))\n",
    "print('Non-Credible avg. sentiment score on title:', np.mean(even_articles['title_sentiment'][even_articles['label']==1]), '+/-', 2*np.std(even_articles['title_sentiment'][even_articles['label']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation (LogisticRegression) Metrics\n",
      "Accuracy Score: 0.539\n",
      "F1 Score: 0.5\n",
      "Confusion matrix:\n",
      "[[993 616]\n",
      " [867 742]]\n"
     ]
    }
   ],
   "source": [
    "#Perform cross validation for logistic regression\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "scores = []\n",
    "f_scores=[]\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_ld = even_articles.iloc[train_index]['title_sentiment'].values\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "    \n",
    "    test_ld = even_articles.iloc[test_index]['title_sentiment'].values\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "\n",
    "    clf = LogisticRegression().fit(train_ld.reshape(-1, 1), train_y)\n",
    "    predictions = clf.predict(test_ld.reshape(-1, 1))\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    f_score = f1_score(test_y, predictions)\n",
    "    score = accuracy_score(test_y, predictions)\n",
    "    scores.append(score)\n",
    "    f_scores.append(f_score)\n",
    "\n",
    "print('Cross Validation (LogisticRegression) Metrics')\n",
    "print('Accuracy Score:', round(sum(scores)/len(scores),3))\n",
    "print('F1 Score:', round(sum(f_scores)/len(f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Punctuation Usage - Specifically \"?\" & \"!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#% of characters in title that are \"?\" or \"!\"\n",
    "def pct_char_quesexcl(title):\n",
    "    try:\n",
    "        ques_excl = [char for char in title if char=='?' or char=='!']\n",
    "        return(len(ques_excl)/len(title))\n",
    "    except:\n",
    "        return(0)        \n",
    "\n",
    "#% of punctuation in text that is \"?\" or \"!\"\n",
    "def pct_punct_quesexcl(in_string):\n",
    "    try:\n",
    "        punct = [char for char in in_string if char in string.punctuation]\n",
    "        ques_excl = [p for p in punct if p=='?' or p=='!']\n",
    "        return(len(ques_excl)/len(punct))\n",
    "    except:\n",
    "        return(0)\n",
    "\n",
    "even_articles['pct_char_quesexcl_title'] = even_articles['title'].apply(pct_char_quesexcl)\n",
    "even_articles['pct_punc_quesexcl_text'] = even_articles['text'].apply(pct_punct_quesexcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credible % of punctuation that is \"!\" or \"?\": 0.007873060526293822 +/- 0.03709217584514235\n",
      "Non-Credible % of punctuation that is \"!\" or \"?\": 0.049374923598625595 +/- 0.14538822720121042\n",
      "\n",
      "Credible % of characters in title that is \"!\" or \"?\": 0.0006084337081119179 +/- 0.007245049650615242\n",
      "Non-Credible % of characters in title that is \"!\" or \"?\": 0.00541318681897949 +/- 0.02228699359987052\n"
     ]
    }
   ],
   "source": [
    "print('Credible % of punctuation that is \"!\" or \"?\":', np.mean(even_articles['pct_punc_quesexcl_text'][even_articles['label']==0]), '+/-', 2*np.std(even_articles['pct_punc_quesexcl_text'][even_articles['label']==0]))\n",
    "print('Non-Credible % of punctuation that is \"!\" or \"?\":', np.mean(even_articles['pct_punc_quesexcl_text'][even_articles['label']==1]), '+/-', 2*np.std(even_articles['pct_punc_quesexcl_text'][even_articles['label']==1]))\n",
    "print()\n",
    "print('Credible % of characters in title that is \"!\" or \"?\":', np.mean(even_articles['pct_char_quesexcl_title'][even_articles['label']==0]), '+/-', 2*np.std(even_articles['pct_char_quesexcl_title'][even_articles['label']==0]))\n",
    "print('Non-Credible % of characters in title that is \"!\" or \"?\":', np.mean(even_articles['pct_char_quesexcl_title'][even_articles['label']==1]), '+/-', 2*np.std(even_articles['pct_char_quesexcl_title'][even_articles['label']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation (LogisticRegression) Metrics\n",
      "Accuracy Score: 0.541\n",
      "F1 Score: 0.468\n",
      "Confusion matrix:\n",
      "[[910 699]\n",
      " [778 831]]\n"
     ]
    }
   ],
   "source": [
    "#Perform cross validation for logistic regression\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "scores = []\n",
    "f_scores=[]\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_pct = even_articles.iloc[train_index]['pct_char_quesexcl_title'].values\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "    \n",
    "    test_pct = even_articles.iloc[test_index]['pct_char_quesexcl_title'].values\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "\n",
    "    clf = LogisticRegression().fit(train_pct.reshape(-1, 1), train_y)\n",
    "    predictions = clf.predict(test_pct.reshape(-1, 1))\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    f_score = f1_score(test_y, predictions)\n",
    "    score = accuracy_score(test_y, predictions)\n",
    "    scores.append(score)\n",
    "    f_scores.append(f_score)\n",
    "\n",
    "print('Cross Validation (LogisticRegression) Metrics')\n",
    "print('Accuracy Score:', round(sum(scores)/len(scores),3))\n",
    "print('F1 Score:', round(sum(f_scores)/len(f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) % words ALL CAPS in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pct_allcaps(title):\n",
    "    try:\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        title = title.translate(translator)\n",
    "        words = title.split()\n",
    "        all_caps = [word for word in words if word.isupper()]\n",
    "        return(len(all_caps)/len(words))\n",
    "    except:\n",
    "        return(0)        \n",
    "\n",
    "even_articles['pct_allcaps_title'] = even_articles['title'].apply(pct_allcaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credible % ALL CAPS words in title: 0.02495169303352554 +/- 0.09646197873766794\n",
      "Non-Credible % ALL CAPS words in title: 0.1268097622440157 +/- 0.40129361119726975\n"
     ]
    }
   ],
   "source": [
    "print('Credible % ALL CAPS words in title:', np.mean(even_articles['pct_allcaps_title'][even_articles['label']==0]), '+/-', 2*np.std(even_articles['pct_allcaps_title'][even_articles['label']==0]))\n",
    "print('Non-Credible % ALL CAPS words in title:', np.mean(even_articles['pct_allcaps_title'][even_articles['label']==1]), '+/-', 2*np.std(even_articles['pct_allcaps_title'][even_articles['label']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation (LogisticRegression) Metrics\n",
      "Accuracy Score: 0.673\n",
      "F1 Score: 0.638\n",
      "Confusion matrix:\n",
      "[[1239  370]\n",
      " [ 682  927]]\n"
     ]
    }
   ],
   "source": [
    "#Perform cross validation for logistic regression\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "scores = []\n",
    "f_scores=[]\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_pct = even_articles.iloc[train_index]['pct_allcaps_title'].values\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "    \n",
    "    test_pct = even_articles.iloc[test_index]['pct_allcaps_title'].values\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "\n",
    "    clf = LogisticRegression().fit(train_pct.reshape(-1, 1), train_y)\n",
    "    predictions = clf.predict(test_pct.reshape(-1, 1))\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    f_score = f1_score(test_y, predictions)\n",
    "    score = accuracy_score(test_y, predictions)\n",
    "    scores.append(score)\n",
    "    f_scores.append(f_score)\n",
    "\n",
    "print('Cross Validation (LogisticRegression) Metrics')\n",
    "print('Accuracy Score:', round(sum(scores)/len(scores),3))\n",
    "print('F1 Score:', round(sum(f_scores)/len(f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1) Logistic Regression & XGBoost classifier on derived \"tonal\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define function to reshape numpy array\n",
    "def reshape_array(array):\n",
    "    flipped_array = array.T\n",
    "    return(flipped_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation (LogisticRegression) Metrics\n",
      "Accuracy Score: 0.721\n",
      "F1 Score: 0.688\n",
      "Confusion matrix:\n",
      "[[1333  276]\n",
      " [ 621  988]]\n",
      "\n",
      "Cross Validation (XGBoost) Metrics\n",
      "Accuracy Score: 0.769\n",
      "F1 Score: 0.748\n",
      "Confusion matrix:\n",
      "[[1369  240]\n",
      " [ 502 1107]]\n"
     ]
    }
   ],
   "source": [
    "#Perform cross validation for logistic regression, XGBoost\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "lr_scores=[]\n",
    "xgb_scores=[]\n",
    "lr_f_scores=[]\n",
    "xgb_f_scores=[]\n",
    "lr_confusion = np.array([[0, 0], [0, 0]])\n",
    "xgb_confusion = np.array([[0, 0], [0, 0]])\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_x = np.array([even_articles.iloc[train_index]['pct_allcaps_title'].values,\n",
    "                        even_articles.iloc[train_index]['pct_punc_quesexcl_text'].values,\n",
    "                        even_articles.iloc[train_index]['pct_char_quesexcl_title'].values,\n",
    "                        even_articles.iloc[train_index]['text_sentiment'].values,\n",
    "                        even_articles.iloc[train_index]['title_sentiment'].values])\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "\n",
    "    test_x = np.array([even_articles.iloc[test_index]['pct_allcaps_title'].values,\n",
    "                       even_articles.iloc[test_index]['pct_punc_quesexcl_text'].values,\n",
    "                       even_articles.iloc[test_index]['pct_char_quesexcl_title'].values,\n",
    "                       even_articles.iloc[test_index]['text_sentiment'].values,\n",
    "                       even_articles.iloc[test_index]['title_sentiment'].values])\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "\n",
    "    #LOGISTIC REGRESSION\n",
    "    lr_clf = LogisticRegression().fit(reshape_array(train_x), train_y)\n",
    "    lr_predictions = lr_clf.predict(reshape_array(test_x))\n",
    "\n",
    "    lr_confusion += confusion_matrix(test_y, lr_predictions)\n",
    "    lr_f_score = f1_score(test_y, lr_predictions)\n",
    "    lr_score = accuracy_score(test_y, lr_predictions)\n",
    "    lr_scores.append(lr_score)\n",
    "    lr_f_scores.append(lr_f_score)\n",
    "\n",
    "    #XGBOOST\n",
    "    xgb_clf = XGBClassifier(max_depth=3, n_estimators=100).fit(reshape_array(train_x), train_y)\n",
    "    xgb_predictions = xgb_clf.predict(reshape_array(test_x))\n",
    "\n",
    "    xgb_confusion += confusion_matrix(test_y, xgb_predictions)\n",
    "    xgb_f_score = f1_score(test_y, xgb_predictions)\n",
    "    xgb_score = accuracy_score(test_y, xgb_predictions)\n",
    "    xgb_scores.append(xgb_score)\n",
    "    xgb_f_scores.append(xgb_f_score)\n",
    "\n",
    "\n",
    "print('Cross Validation (LogisticRegression) Metrics')\n",
    "print('Accuracy Score:', round(sum(lr_scores)/len(lr_scores),3))\n",
    "print('F1 Score:', round(sum(lr_f_scores)/len(lr_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(lr_confusion)\n",
    "print()\n",
    "print('Cross Validation (XGBoost) Metrics')\n",
    "print('Accuracy Score:', round(sum(xgb_scores)/len(xgb_scores),3))\n",
    "print('F1 Score:', round(sum(xgb_f_scores)/len(xgb_f_scores),3))\n",
    "print('Confusion matrix:')\n",
    "print(xgb_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Check for Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cred_fp = '/ebs_volume/data/Credible/'\n",
    "ncred_fp = '/ebs_volume/data/notCredible/'\n",
    "\n",
    "articles = pd.DataFrame(columns=('label',\n",
    "                                 'text',\n",
    "                                 'title',\n",
    "                                 'date',\n",
    "                                 'source'))\n",
    "i = 0    \n",
    "for root, dirs, files in os.walk(cred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print curr_file\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    articles.loc[i] = [0,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "for root, dirs, files in os.walk(ncred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print curr_file\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    articles.loc[i] = [1,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6235\n",
      "5182\n"
     ]
    }
   ],
   "source": [
    "#Remove duplicate articles\n",
    "print(len(articles))\n",
    "unique_articles = articles.drop_duplicates(subset = 'text')\n",
    "print(len(unique_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5182\n",
      "5048\n"
     ]
    }
   ],
   "source": [
    "#Remove really short articles (<=200 chars)\n",
    "print(len(unique_articles))\n",
    "unique_articles = unique_articles[unique_articles[\"text\"].str.len()>200]\n",
    "print(len(unique_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_creds = unique_articles[unique_articles[\"label\"]==0.0]\n",
    "all_noncreds = unique_articles[unique_articles[\"label\"]==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credible_sources = list(set(unique_articles[\"source\"][unique_articles[\"label\"]==0]))\n",
    "non_credible_sources = list(set(unique_articles[\"source\"][unique_articles[\"label\"]==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove sources that don't contain enough articles for testing\n",
    "credible_sources.remove('new-york-times')\n",
    "credible_sources.remove('nature')\n",
    "non_credible_sources.remove('empirenews')\n",
    "non_credible_sources.remove('darkmoon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shuffle lists and divide in 5 equal(ish) parts\n",
    "random.shuffle(credible_sources)\n",
    "random.shuffle(non_credible_sources)\n",
    "credible_sources_array=np.array(credible_sources)\n",
    "non_credible_sources_array=np.array(non_credible_sources)\n",
    "\n",
    "credible_sources_arrays = np.split(credible_sources_array, [2, 4, 6, 8, 10])\n",
    "non_credible_sources_arrays = np.split(non_credible_sources_array, [3, 5, 7, 9, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credible_sources_arrays = credible_sources_arrays[:5]\n",
    "non_credible_sources_arrays = non_credible_sources_arrays[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MNB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.793\n",
      "F1 Score: 0.744\n",
      "Confusion matrix:\n",
      "[[375   6]\n",
      " [152 229]]\n",
      "\n",
      "[SVM] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.833\n",
      "F1 Score: 0.827\n",
      "Confusion matrix:\n",
      "[[332  49]\n",
      " [ 78 303]]\n",
      "\n",
      "[XGB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.693\n",
      "F1 Score: 0.619\n",
      "Confusion matrix:\n",
      "[[338  43]\n",
      " [191 190]]\n",
      "\n",
      "COMPLETED 1/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.924\n",
      "F1 Score: 0.919\n",
      "Confusion matrix:\n",
      "[[374   7]\n",
      " [ 51 330]]\n",
      "\n",
      "[SVM] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.891\n",
      "F1 Score: 0.893\n",
      "Confusion matrix:\n",
      "[[331  50]\n",
      " [ 33 348]]\n",
      "\n",
      "[XGB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.776\n",
      "F1 Score: 0.751\n",
      "Confusion matrix:\n",
      "[[333  48]\n",
      " [123 258]]\n",
      "\n",
      "COMPLETED 2/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.848\n",
      "F1 Score: 0.823\n",
      "Confusion matrix:\n",
      "[[377   4]\n",
      " [112 269]]\n",
      "\n",
      "[SVM] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.843\n",
      "F1 Score: 0.843\n",
      "Confusion matrix:\n",
      "[[320  61]\n",
      " [ 59 322]]\n",
      "\n",
      "[XGB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.675\n",
      "F1 Score: 0.603\n",
      "Confusion matrix:\n",
      "[[326  55]\n",
      " [193 188]]\n",
      "\n",
      "COMPLETED 3/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.924\n",
      "F1 Score: 0.919\n",
      "Confusion matrix:\n",
      "[[376   5]\n",
      " [ 53 328]]\n",
      "\n",
      "[SVM] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.879\n",
      "F1 Score: 0.886\n",
      "Confusion matrix:\n",
      "[[312  69]\n",
      " [ 23 358]]\n",
      "\n",
      "[XGB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.682\n",
      "F1 Score: 0.615\n",
      "Confusion matrix:\n",
      "[[327  54]\n",
      " [188 193]]\n",
      "\n",
      "COMPLETED 4/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.923\n",
      "F1 Score: 0.917\n",
      "Confusion matrix:\n",
      "[[377   4]\n",
      " [ 55 326]]\n",
      "\n",
      "[SVM] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.907\n",
      "F1 Score: 0.911\n",
      "Confusion matrix:\n",
      "[[326  55]\n",
      " [ 16 365]]\n",
      "\n",
      "[XGB] -- Test on ['the-wall-street-journal', 'bbc-news'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 762\n",
      "Accuracy Score: 0.892\n",
      "F1 Score: 0.895\n",
      "Confusion matrix:\n",
      "[[330  51]\n",
      " [ 31 350]]\n",
      "\n",
      "COMPLETED 5/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['latimes', 'reuters'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.794\n",
      "F1 Score: 0.762\n",
      "Confusion matrix:\n",
      "[[283  21]\n",
      " [104 200]]\n",
      "\n",
      "[SVM] -- Test on ['latimes', 'reuters'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.875\n",
      "F1 Score: 0.864\n",
      "Confusion matrix:\n",
      "[[291  13]\n",
      " [ 63 241]]\n",
      "\n",
      "[XGB] -- Test on ['latimes', 'reuters'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.696\n",
      "F1 Score: 0.611\n",
      "Confusion matrix:\n",
      "[[278  26]\n",
      " [159 145]]\n",
      "\n",
      "COMPLETED 6/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['latimes', 'reuters'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.91\n",
      "F1 Score: 0.91\n",
      "Confusion matrix:\n",
      "[[276  28]\n",
      " [ 27 277]]\n",
      "\n",
      "[SVM] -- Test on ['latimes', 'reuters'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.929\n",
      "F1 Score: 0.927\n",
      "Confusion matrix:\n",
      "[[291  13]\n",
      " [ 30 274]]\n",
      "\n",
      "[XGB] -- Test on ['latimes', 'reuters'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.816\n",
      "F1 Score: 0.796\n",
      "Confusion matrix:\n",
      "[[277  27]\n",
      " [ 85 219]]\n",
      "\n",
      "COMPLETED 7/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['latimes', 'reuters'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.87\n",
      "F1 Score: 0.86\n",
      "Confusion matrix:\n",
      "[[287  17]\n",
      " [ 62 242]]\n",
      "\n",
      "[SVM] -- Test on ['latimes', 'reuters'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.914\n",
      "F1 Score: 0.909\n",
      "Confusion matrix:\n",
      "[[295   9]\n",
      " [ 43 261]]\n",
      "\n",
      "[XGB] -- Test on ['latimes', 'reuters'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.688\n",
      "F1 Score: 0.612\n",
      "Confusion matrix:\n",
      "[[268  36]\n",
      " [154 150]]\n",
      "\n",
      "COMPLETED 8/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['latimes', 'reuters'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.911\n",
      "F1 Score: 0.908\n",
      "Confusion matrix:\n",
      "[[286  18]\n",
      " [ 36 268]]\n",
      "\n",
      "[SVM] -- Test on ['latimes', 'reuters'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.939\n",
      "F1 Score: 0.939\n",
      "Confusion matrix:\n",
      "[[286  18]\n",
      " [ 19 285]]\n",
      "\n",
      "[XGB] -- Test on ['latimes', 'reuters'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.696\n",
      "F1 Score: 0.628\n",
      "Confusion matrix:\n",
      "[[267  37]\n",
      " [148 156]]\n",
      "\n",
      "COMPLETED 9/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['latimes', 'reuters'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.901\n",
      "F1 Score: 0.901\n",
      "Confusion matrix:\n",
      "[[274  30]\n",
      " [ 30 274]]\n",
      "\n",
      "[SVM] -- Test on ['latimes', 'reuters'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.957\n",
      "F1 Score: 0.958\n",
      "Confusion matrix:\n",
      "[[289  15]\n",
      " [ 11 293]]\n",
      "\n",
      "[XGB] -- Test on ['latimes', 'reuters'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 608\n",
      "Accuracy Score: 0.882\n",
      "F1 Score: 0.883\n",
      "Confusion matrix:\n",
      "[[265  39]\n",
      " [ 33 271]]\n",
      "\n",
      "COMPLETED 10/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-washington-post', 'usa-today'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.74\n",
      "F1 Score: 0.749\n",
      "Confusion matrix:\n",
      "[[278 118]\n",
      " [ 88 308]]\n",
      "\n",
      "[SVM] -- Test on ['the-washington-post', 'usa-today'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.813\n",
      "F1 Score: 0.812\n",
      "Confusion matrix:\n",
      "[[324  72]\n",
      " [ 76 320]]\n",
      "\n",
      "[XGB] -- Test on ['the-washington-post', 'usa-today'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.692\n",
      "F1 Score: 0.646\n",
      "Confusion matrix:\n",
      "[[325  71]\n",
      " [173 223]]\n",
      "\n",
      "COMPLETED 11/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-washington-post', 'usa-today'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.824\n",
      "F1 Score: 0.842\n",
      "Confusion matrix:\n",
      "[[282 114]\n",
      " [ 25 371]]\n",
      "\n",
      "[SVM] -- Test on ['the-washington-post', 'usa-today'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.893\n",
      "F1 Score: 0.896\n",
      "Confusion matrix:\n",
      "[[340  56]\n",
      " [ 29 367]]\n",
      "\n",
      "[XGB] -- Test on ['the-washington-post', 'usa-today'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.774\n",
      "F1 Score: 0.764\n",
      "Confusion matrix:\n",
      "[[324  72]\n",
      " [107 289]]\n",
      "\n",
      "COMPLETED 12/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-washington-post', 'usa-today'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.799\n",
      "F1 Score: 0.812\n",
      "Confusion matrix:\n",
      "[[289 107]\n",
      " [ 52 344]]\n",
      "\n",
      "[SVM] -- Test on ['the-washington-post', 'usa-today'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.854\n",
      "F1 Score: 0.854\n",
      "Confusion matrix:\n",
      "[[338  58]\n",
      " [ 58 338]]\n",
      "\n",
      "[XGB] -- Test on ['the-washington-post', 'usa-today'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.674\n",
      "F1 Score: 0.622\n",
      "Confusion matrix:\n",
      "[[322  74]\n",
      " [184 212]]\n",
      "\n",
      "COMPLETED 13/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-washington-post', 'usa-today'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.831\n",
      "F1 Score: 0.847\n",
      "Confusion matrix:\n",
      "[[287 109]\n",
      " [ 25 371]]\n",
      "\n",
      "[SVM] -- Test on ['the-washington-post', 'usa-today'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.893\n",
      "F1 Score: 0.9\n",
      "Confusion matrix:\n",
      "[[326  70]\n",
      " [ 15 381]]\n",
      "\n",
      "[XGB] -- Test on ['the-washington-post', 'usa-today'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.702\n",
      "F1 Score: 0.652\n",
      "Confusion matrix:\n",
      "[[335  61]\n",
      " [175 221]]\n",
      "\n",
      "COMPLETED 14/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-washington-post', 'usa-today'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.851\n",
      "F1 Score: 0.866\n",
      "Confusion matrix:\n",
      "[[292 104]\n",
      " [ 14 382]]\n",
      "\n",
      "[SVM] -- Test on ['the-washington-post', 'usa-today'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.905\n",
      "F1 Score: 0.911\n",
      "Confusion matrix:\n",
      "[[332  64]\n",
      " [ 11 385]]\n",
      "\n",
      "[XGB] -- Test on ['the-washington-post', 'usa-today'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 792\n",
      "Accuracy Score: 0.832\n",
      "F1 Score: 0.84\n",
      "Confusion matrix:\n",
      "[[309  87]\n",
      " [ 46 350]]\n",
      "\n",
      "COMPLETED 15/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['bostonglobe', 'national-geographic'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.737\n",
      "F1 Score: 0.707\n",
      "Confusion matrix:\n",
      "[[195  37]\n",
      " [ 85 147]]\n",
      "\n",
      "[SVM] -- Test on ['bostonglobe', 'national-geographic'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.836\n",
      "F1 Score: 0.83\n",
      "Confusion matrix:\n",
      "[[203  29]\n",
      " [ 47 185]]\n",
      "\n",
      "[XGB] -- Test on ['bostonglobe', 'national-geographic'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.664\n",
      "F1 Score: 0.616\n",
      "Confusion matrix:\n",
      "[[183  49]\n",
      " [107 125]]\n",
      "\n",
      "COMPLETED 16/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['bostonglobe', 'national-geographic'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.804\n",
      "F1 Score: 0.817\n",
      "Confusion matrix:\n",
      "[[170  62]\n",
      " [ 29 203]]\n",
      "\n",
      "[SVM] -- Test on ['bostonglobe', 'national-geographic'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.806\n",
      "F1 Score: 0.819\n",
      "Confusion matrix:\n",
      "[[171  61]\n",
      " [ 29 203]]\n",
      "\n",
      "[XGB] -- Test on ['bostonglobe', 'national-geographic'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.744\n",
      "F1 Score: 0.737\n",
      "Confusion matrix:\n",
      "[[178  54]\n",
      " [ 65 167]]\n",
      "\n",
      "COMPLETED 17/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['bostonglobe', 'national-geographic'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.804\n",
      "F1 Score: 0.808\n",
      "Confusion matrix:\n",
      "[[182  50]\n",
      " [ 41 191]]\n",
      "\n",
      "[SVM] -- Test on ['bostonglobe', 'national-geographic'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.834\n",
      "F1 Score: 0.837\n",
      "Confusion matrix:\n",
      "[[189  43]\n",
      " [ 34 198]]\n",
      "\n",
      "[XGB] -- Test on ['bostonglobe', 'national-geographic'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.664\n",
      "F1 Score: 0.604\n",
      "Confusion matrix:\n",
      "[[189  43]\n",
      " [113 119]]\n",
      "\n",
      "COMPLETED 18/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['bostonglobe', 'national-geographic'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.845\n",
      "F1 Score: 0.85\n",
      "Confusion matrix:\n",
      "[[188  44]\n",
      " [ 28 204]]\n",
      "\n",
      "[SVM] -- Test on ['bostonglobe', 'national-geographic'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.873\n",
      "F1 Score: 0.881\n",
      "Confusion matrix:\n",
      "[[186  46]\n",
      " [ 13 219]]\n",
      "\n",
      "[XGB] -- Test on ['bostonglobe', 'national-geographic'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.67\n",
      "F1 Score: 0.635\n",
      "Confusion matrix:\n",
      "[[178  54]\n",
      " [ 99 133]]\n",
      "\n",
      "COMPLETED 19/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['bostonglobe', 'national-geographic'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.78\n",
      "F1 Score: 0.802\n",
      "Confusion matrix:\n",
      "[[156  76]\n",
      " [ 26 206]]\n",
      "\n",
      "[SVM] -- Test on ['bostonglobe', 'national-geographic'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.81\n",
      "F1 Score: 0.834\n",
      "Confusion matrix:\n",
      "[[155  77]\n",
      " [ 11 221]]\n",
      "\n",
      "[XGB] -- Test on ['bostonglobe', 'national-geographic'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 464\n",
      "Accuracy Score: 0.823\n",
      "F1 Score: 0.84\n",
      "Confusion matrix:\n",
      "[[166  66]\n",
      " [ 16 216]]\n",
      "\n",
      "COMPLETED 20/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-new-york-times', 'independent'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.751\n",
      "F1 Score: 0.747\n",
      "Confusion matrix:\n",
      "[[252  77]\n",
      " [ 87 242]]\n",
      "\n",
      "[SVM] -- Test on ['the-new-york-times', 'independent'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.827\n",
      "F1 Score: 0.816\n",
      "Confusion matrix:\n",
      "[[291  38]\n",
      " [ 76 253]]\n",
      "\n",
      "[XGB] -- Test on ['the-new-york-times', 'independent'] & ['ItMakesSenseBlog', 'activistpost', 'infostormer']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.666\n",
      "F1 Score: 0.6\n",
      "Confusion matrix:\n",
      "[[273  56]\n",
      " [164 165]]\n",
      "\n",
      "COMPLETED 21/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-new-york-times', 'independent'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.845\n",
      "F1 Score: 0.858\n",
      "Confusion matrix:\n",
      "[[248  81]\n",
      " [ 21 308]]\n",
      "\n",
      "[SVM] -- Test on ['the-new-york-times', 'independent'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.894\n",
      "F1 Score: 0.896\n",
      "Confusion matrix:\n",
      "[[288  41]\n",
      " [ 29 300]]\n",
      "\n",
      "[XGB] -- Test on ['the-new-york-times', 'independent'] & ['gopthedailydose', 'success-street']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.748\n",
      "F1 Score: 0.738\n",
      "Confusion matrix:\n",
      "[[258  71]\n",
      " [ 95 234]]\n",
      "\n",
      "COMPLETED 22/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-new-york-times', 'independent'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.812\n",
      "F1 Score: 0.819\n",
      "Confusion matrix:\n",
      "[[254  75]\n",
      " [ 49 280]]\n",
      "\n",
      "[SVM] -- Test on ['the-new-york-times', 'independent'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.865\n",
      "F1 Score: 0.864\n",
      "Confusion matrix:\n",
      "[[286  43]\n",
      " [ 46 283]]\n",
      "\n",
      "[XGB] -- Test on ['the-new-york-times', 'independent'] & ['usfanzone', 'dcclothesline']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.663\n",
      "F1 Score: 0.593\n",
      "Confusion matrix:\n",
      "[[274  55]\n",
      " [167 162]]\n",
      "\n",
      "COMPLETED 23/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-new-york-times', 'independent'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.856\n",
      "F1 Score: 0.865\n",
      "Confusion matrix:\n",
      "[[259  70]\n",
      " [ 25 304]]\n",
      "\n",
      "[SVM] -- Test on ['the-new-york-times', 'independent'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.904\n",
      "F1 Score: 0.909\n",
      "Confusion matrix:\n",
      "[[281  48]\n",
      " [ 15 314]]\n",
      "\n",
      "[XGB] -- Test on ['the-new-york-times', 'independent'] & ['usasupreme', 'rickwells']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.661\n",
      "F1 Score: 0.597\n",
      "Confusion matrix:\n",
      "[[270  59]\n",
      " [164 165]]\n",
      "\n",
      "COMPLETED 24/25 ITERATIONS\n",
      "\n",
      "[MNB] -- Test on ['the-new-york-times', 'independent'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.85\n",
      "F1 Score: 0.862\n",
      "Confusion matrix:\n",
      "[[249  80]\n",
      " [ 19 310]]\n",
      "\n",
      "[SVM] -- Test on ['the-new-york-times', 'independent'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.926\n",
      "F1 Score: 0.929\n",
      "Confusion matrix:\n",
      "[[290  39]\n",
      " [ 10 319]]\n",
      "\n",
      "[XGB] -- Test on ['the-new-york-times', 'independent'] & ['usanewsflash', 'usapoliticsnow']\n",
      "Total articles classified: 658\n",
      "Accuracy Score: 0.84\n",
      "F1 Score: 0.85\n",
      "Confusion matrix:\n",
      "[[255  74]\n",
      " [ 31 298]]\n",
      "\n",
      "COMPLETED 25/25 ITERATIONS\n",
      "\n",
      "*---------------------------*\n",
      "GENERALIZATION (MNB) Metrics\n",
      "Accuracy Score: 0.837\n",
      "F1 Score: 0.837\n",
      "Confusion matrix:\n",
      "[[6866 1344]\n",
      " [1296 6914]]\n",
      "\n",
      "GENERALIZATION (SVM) Metrics\n",
      "Accuracy Score: 0.876\n",
      "F1 Score: 0.878\n",
      "Confusion matrix:\n",
      "[[7073 1137]\n",
      " [ 874 7336]]\n",
      "\n",
      "GENERALIZATION (XGB) Metrics\n",
      "Accuracy Score: 0.732\n",
      "F1 Score: 0.694\n",
      "Confusion matrix:\n",
      "[[6848 1362]\n",
      " [3011 5199]]\n"
     ]
    }
   ],
   "source": [
    "scores_mnb = []\n",
    "f_scores_mnb = []\n",
    "confusion_mnb = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "scores_svm = []\n",
    "f_scores_svm = []\n",
    "confusion_svm = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "scores_xgb = []\n",
    "f_scores_xgb = []\n",
    "confusion_xgb = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "i=0\n",
    "\n",
    "for cred_array in credible_sources_arrays:\n",
    "    #1) Generate Train/Test splits by source\n",
    "    cred_list = list(cred_array)    \n",
    "    holdout_creds = all_creds[all_creds[\"source\"].isin(cred_list)]\n",
    "    train_creds = all_creds[~all_creds[\"source\"].isin(cred_list)]\n",
    "    \n",
    "    for non_cred_array in non_credible_sources_arrays:\n",
    "        non_cred_list = list(non_cred_array)\n",
    "        holdout_noncreds = all_noncreds[all_noncreds[\"source\"].isin(non_cred_list)].sample(n=len(holdout_creds))\n",
    "        train_noncreds = all_noncreds[~all_noncreds[\"source\"].isin(non_cred_list)].sample(n=len(train_creds))\n",
    "        \n",
    "        train_articles = pd.concat([train_creds, train_noncreds])\n",
    "        test_articles = pd.concat([holdout_creds, holdout_noncreds])\n",
    "        \n",
    "        #2) Text preprocessing for bag of words (content-based) classifiers\n",
    "        train_articles['filtered_text'] = train_articles['text'].apply(remove_cap_punc)\n",
    "        test_articles['filtered_text'] = test_articles['text'].apply(remove_cap_punc)\n",
    "        \n",
    "        train_articles['filtered_text'] = train_articles.apply(lambda x: remove_overfit_words(x['filtered_text'], wordlist=wordlist, sourcelist=sourcelist, phraselist=phraselist), axis=1)\n",
    "        test_articles['filtered_text'] = test_articles.apply(lambda x: remove_overfit_words(x['filtered_text'], wordlist=wordlist, sourcelist=sourcelist, phraselist=phraselist), axis=1)\n",
    "        \n",
    "        train_articles['filtered_text'] = train_articles['filtered_text'].apply(remove_shortwords)\n",
    "        test_articles['filtered_text'] = test_articles['filtered_text'].apply(remove_shortwords)\n",
    "        \n",
    "        train_articles['filtered_text'] = train_articles['filtered_text'].apply(remove_stopwords)\n",
    "        train_articles['filtered_text'] = train_articles['filtered_text'].apply(remove_shortwords)\n",
    "        test_articles['filtered_text'] = test_articles['filtered_text'].apply(remove_stopwords)\n",
    "        test_articles['filtered_text'] = test_articles['filtered_text'].apply(remove_shortwords)\n",
    "        \n",
    "        #3) MNB classification\n",
    "        count_vect = CountVectorizer(analyzer='word', ngram_range=(1,1), min_df=0)\n",
    "        tfidf = TfidfTransformer()\n",
    "    \n",
    "        confusion = np.array([[0, 0], [0, 0]])\n",
    "        train_text = train_articles['filtered_text'].values\n",
    "        train_counts = count_vect.fit_transform(train_text)\n",
    "        train_tfidf = tfidf.fit_transform(train_counts)\n",
    "        train_y = train_articles['label'].values\n",
    "\n",
    "        test_text = test_articles['filtered_text'].values\n",
    "        test_counts = count_vect.transform(test_text)\n",
    "        test_tfidf = tfidf.transform(test_counts)\n",
    "        test_y = test_articles['label'].values\n",
    "\n",
    "        mnb_clf = MultinomialNB().fit(train_tfidf, train_y)\n",
    "        mnb_predictions = mnb_clf.predict(test_tfidf)\n",
    "\n",
    "        confusion_mnb += confusion_matrix(test_y, mnb_predictions)\n",
    "        f_score_mnb = f1_score(test_y, mnb_predictions)\n",
    "        score_mnb = accuracy_score(test_y, mnb_predictions)\n",
    "        scores_mnb.append(score_mnb)\n",
    "        f_scores_mnb.append(f_score_mnb)\n",
    "        \n",
    "        print(\"[MNB] -- Test on {0} & {1}\".format(cred_list, non_cred_list))\n",
    "        print('Total articles classified:', len(mnb_predictions))\n",
    "        print('Accuracy Score:', round(score_mnb, 3))\n",
    "        print('F1 Score:', round(f_score_mnb, 3))\n",
    "        print('Confusion matrix:')\n",
    "        print(confusion_matrix(test_y, mnb_predictions))\n",
    "        print()\n",
    "        \n",
    "        #4) Linear SVM Classification\n",
    "        svm_clf = SVC(kernel=\"linear\").fit(train_tfidf, train_y)\n",
    "        svm_predictions = svm_clf.predict(test_tfidf)\n",
    "\n",
    "        confusion_svm += confusion_matrix(test_y, svm_predictions)\n",
    "        f_score_svm = f1_score(test_y, svm_predictions)\n",
    "        score_svm = accuracy_score(test_y, svm_predictions)\n",
    "        scores_svm.append(score_svm)\n",
    "        f_scores_svm.append(f_score_svm)\n",
    "        \n",
    "        print(\"[SVM] -- Test on {0} & {1}\".format(cred_list, non_cred_list))\n",
    "        print('Total articles classified:', len(svm_predictions))\n",
    "        print('Accuracy Score:', round(score_svm, 3))\n",
    "        print('F1 Score:', round(f_score_svm, 3))\n",
    "        print('Confusion matrix:')\n",
    "        print(confusion_matrix(test_y, svm_predictions))\n",
    "        print()\n",
    "        \n",
    "        #5) Text preprocessing for tone-based classification\n",
    "        train_articles['sentences'] = train_articles['text'].apply(split_into_sentences)\n",
    "        train_articles['text_sentiment'] = train_articles['sentences'].apply(sent_analysis)\n",
    "        train_articles['title_sentiment'] = train_articles.apply(lambda x: sent_analysis(x['title'], uoa=\"string\"), axis=1)\n",
    "        test_articles['sentences'] = test_articles['text'].apply(split_into_sentences)\n",
    "        test_articles['text_sentiment'] = test_articles['sentences'].apply(sent_analysis)\n",
    "        test_articles['title_sentiment'] = test_articles.apply(lambda x: sent_analysis(x['title'], uoa=\"string\"), axis=1)\n",
    "        \n",
    "        train_articles['pct_char_quesexcl_title'] = train_articles['title'].apply(pct_char_quesexcl)\n",
    "        train_articles['pct_punc_quesexcl_text'] = train_articles['text'].apply(pct_punct_quesexcl)\n",
    "        test_articles['pct_char_quesexcl_title'] = test_articles['title'].apply(pct_char_quesexcl)\n",
    "        test_articles['pct_punc_quesexcl_text'] = test_articles['text'].apply(pct_punct_quesexcl)\n",
    "        \n",
    "        train_articles['pct_allcaps_title'] = train_articles['title'].apply(pct_allcaps)\n",
    "        test_articles['pct_allcaps_title'] = test_articles['title'].apply(pct_allcaps)\n",
    "        \n",
    "        #6) XGBoost Classification\n",
    "        xgb_train_x = np.array([train_articles['pct_allcaps_title'].values,\n",
    "                                train_articles['pct_punc_quesexcl_text'].values,\n",
    "                                train_articles['pct_char_quesexcl_title'].values,\n",
    "                                train_articles['text_sentiment'].values,\n",
    "                                train_articles['title_sentiment'].values])\n",
    "        xgb_train_y = train_articles['label'].values\n",
    "        \n",
    "        xgb_test_x = np.array([test_articles['pct_allcaps_title'].values,\n",
    "                               test_articles['pct_punc_quesexcl_text'].values,\n",
    "                               test_articles['pct_char_quesexcl_title'].values,\n",
    "                               test_articles['text_sentiment'].values,\n",
    "                               test_articles['title_sentiment'].values])\n",
    "        xgb_test_y = test_articles['label'].values\n",
    "        \n",
    "        xgb_clf = XGBClassifier(max_depth=3, n_estimators=100).fit(reshape_array(xgb_train_x), xgb_train_y)\n",
    "        xgb_predictions = xgb_clf.predict(reshape_array(xgb_test_x))\n",
    "\n",
    "        confusion_xgb += confusion_matrix(xgb_test_y, xgb_predictions)\n",
    "        f_score_xgb = f1_score(xgb_test_y, xgb_predictions)\n",
    "        score_xgb = accuracy_score(xgb_test_y, xgb_predictions)\n",
    "        scores_xgb.append(score_xgb)\n",
    "        f_scores_xgb.append(f_score_xgb)\n",
    "        \n",
    "        print(\"[XGB] -- Test on {0} & {1}\".format(cred_list, non_cred_list))\n",
    "        print('Total articles classified:', len(xgb_predictions))\n",
    "        print('Accuracy Score:', round(score_xgb, 3))\n",
    "        print('F1 Score:', round(f_score_xgb, 3))\n",
    "        print('Confusion matrix:')\n",
    "        print(confusion_matrix(xgb_test_y, xgb_predictions))\n",
    "        print()\n",
    "                \n",
    "        i+=1\n",
    "        print(\"COMPLETED {0}/{1} ITERATIONS\".format(i,len(credible_sources_arrays)*len(non_credible_sources_arrays)))\n",
    "        print()\n",
    "        \n",
    "print(\"*---------------------------*\")        \n",
    "print('GENERALIZATION (MNB) Metrics')\n",
    "print('Accuracy Score:', round(sum(scores_mnb)/len(scores_mnb),3))\n",
    "print('F1 Score:', round(sum(f_scores_mnb)/len(f_scores_mnb),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_mnb)\n",
    "print()\n",
    "\n",
    "print('GENERALIZATION (SVM) Metrics')\n",
    "print('Accuracy Score:', round(sum(scores_svm)/len(scores_svm),3))\n",
    "print('F1 Score:', round(sum(f_scores_svm)/len(f_scores_svm),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_svm) \n",
    "print()\n",
    "\n",
    "print('GENERALIZATION (XGB) Metrics')\n",
    "print('Accuracy Score:', round(sum(scores_xgb)/len(scores_xgb),3))\n",
    "print('F1 Score:', round(sum(f_scores_xgb)/len(f_scores_xgb),3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pizza_gate_text = \"\"\"Comet Pizza is a pizza place owned by James Alefantis, who is the former gay boyfriend of David Brock, the CEO of Correct The Record. It has been the venue for dozens of events for the Hillary campaign staff. John Podesta has had campaign fundraisers there for both Barack Obama and Hillary Clinton. John’s brother and business partner Tony Podesta has his birthday party there every year. [https://i.sli.mg/1MqPHA.png]\n",
    "\n",
    "It’s also a dive that according to reviews and photos has hidden bathroom doors and creepy murals. The bathrooms in particular have murals exclusively of nude women, as well as a great deal of graffiti relating to sex. Reviews of the restaurant are bizarrely polarized. Websites describing it positively note that there are regularly “unsupervised children running around”. Their menu include a pedophilic symbol, as do the signs and decorations of other neighboring businesses.\n",
    "\n",
    "The music acts and the posters promoting same acts are bizarre in their presentation, content, and lyrical focus, but are still promoted as being “for all ages”. The overtly sexual content would suggest otherwise.\n",
    "\n",
    "The same has taken place in reference to videos recorded inside Comet Ping Pong by people that frequent their establishment as well as video referencing Comet Ping Pong positively from the exterior.\n",
    "\n",
    "While initially not the central focus of the investigation at the onset, Comet Ping Pong is a much more overt and much more disturbing hub of coincidences. Everyone associated with the business is making semi-overt, semi-tongue-in-cheek, and semi-sarcastic inferences towards sex with minors. The artists that work for and with the business also generate nothing but cultish imagery of disembodiment, blood, beheadings, sex, and of course pizza.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_text: 275 words, 1761 characters\n",
      "\n",
      "Comet Pizza is a pizza place owned by James Alefantis, who is the former gay boyfriend of David Brock, the CEO of Correct The Record. It has been the venue for dozens of events for the Hillary campaign staff. John Podesta has had campaign fundraisers there for both Barack Obama and Hillary Clinton. John’s brother and business partner Tony Podesta has his birthday party there every year. [https://i.sli.mg/1MqPHA.png]\n",
      "\n",
      "It’s also a dive that according to reviews and photos has hidden bathroom doors and creepy murals. The bathrooms in particular have murals exclusively of nude women, as well as a great deal of graffiti relating to sex. Reviews of the restaurant are bizarrely polarized. Websites describing it positively note that there are regularly “unsupervised children running around”. Their menu include a pedophilic symbol, as do the signs and decorations of other neighboring businesses.\n",
      "\n",
      "The music acts and the posters promoting same acts are bizarre in their presentation, content, and lyrical focus, but are still promoted as being “for all ages”. The overtly sexual content would suggest otherwise.\n",
      "\n",
      "The same has taken place in reference to videos recorded inside Comet Ping Pong by people that frequent their establishment as well as video referencing Comet Ping Pong positively from the exterior.\n",
      "\n",
      "While initially not the central focus of the investigation at the onset, Comet Ping Pong is a much more overt and much more disturbing hub of coincidences. Everyone associated with the business is making semi-overt, semi-tongue-in-cheek, and semi-sarcastic inferences towards sex with minors. The artists that work for and with the business also generate nothing but cultish imagery of disembodiment, blood, beheadings, sex, and of course pizza.\n",
      "\n",
      "Removed cap/punc: 275 words, 1714 characters\n",
      "\n",
      "comet pizza is a pizza place owned by james alefantis who is the former gay boyfriend of david brock the ceo of correct the record it has been the venue for dozens of events for the hillary campaign staff john podesta has had campaign fundraisers there for both barack obama and hillary clinton john’s brother and business partner tony podesta has his birthday party there every year httpsislimg1mqphapng it’s also a dive that according to reviews and photos has hidden bathroom doors and creepy murals the bathrooms in particular have murals exclusively of nude women as well as a great deal of graffiti relating to sex reviews of the restaurant are bizarrely polarized websites describing it positively note that there are regularly “unsupervised children running around” their menu include a pedophilic symbol as do the signs and decorations of other neighboring businesses the music acts and the posters promoting same acts are bizarre in their presentation content and lyrical focus but are still promoted as being “for all ages” the overtly sexual content would suggest otherwise the same has taken place in reference to videos recorded inside comet ping pong by people that frequent their establishment as well as video referencing comet ping pong positively from the exterior while initially not the central focus of the investigation at the onset comet ping pong is a much more overt and much more disturbing hub of coincidences everyone associated with the business is making semiovert semitongueincheek and semisarcastic inferences towards sex with minors the artists that work for and with the business also generate nothing but cultish imagery of disembodiment blood beheadings sex and of course pizza\n",
      "\n",
      "Removed overfit words/phrases: 274 words, 1708 characters\n",
      "\n",
      "comet pizza is a pizza place owned by james alefantis who is the former gay boyfriend of david brock the ceo of correct the record it has been the venue for dozens of events for the hillary campaign staff john podesta has had campaign fundraisers there for both barack obama and hillary clinton john’s brother and business partner tony podesta has his birthday party there every year httpsislimg1mqphapng it’s also a dive that according to reviews and photos has hidden bathroom doors and creepy murals the bathrooms in particular have murals exclusively of nude women as well as a great deal of graffiti relating to sex reviews of the restaurant are bizarrely polarized websites describing it positively note that there are regularly “unsupervised children running around” their menu include a pedophilic symbol as do the signs and decorations of other neighboring businesses the music acts and the posters promoting same acts are bizarre in their presentation content and lyrical focus but are still promoted as being “for all ages” the overtly sexual content would suggest otherwise the same has taken place in reference to videos recorded inside comet ping pong by people that frequent their establishment as well as referencing comet ping pong positively from the exterior while initially not the central focus of the investigation at the onset comet ping pong is a much more overt and much more disturbing hub of coincidences everyone associated with the business is making semiovert semitongueincheek and semisarcastic inferences towards sex with minors the artists that work for and with the business also generate nothing but cultish imagery of disembodiment blood beheadings sex and of course pizza\n",
      "\n",
      "Removed short words: 236 words, 1599 characters\n",
      "\n",
      "comet pizza pizza place owned james alefantis who the former gay boyfriend david brock the ceo correct the record has been the venue for dozens events for the hillary campaign staff john podesta has had campaign fundraisers there for both barack obama and hillary clinton john’s brother and business partner tony podesta has his birthday party there every year httpsislimg1mqphapng it’s also dive that according reviews and photos has hidden bathroom doors and creepy murals the bathrooms particular have murals exclusively nude women well great deal graffiti relating sex reviews the restaurant are bizarrely polarized websites describing positively note that there are regularly “unsupervised children running around” their menu include pedophilic symbol the signs and decorations other neighboring businesses the music acts and the posters promoting same acts are bizarre their presentation content and lyrical focus but are still promoted being “for all ages” the overtly sexual content would suggest otherwise the same has taken place reference videos recorded inside comet ping pong people that frequent their establishment well referencing comet ping pong positively from the exterior while initially not the central focus the investigation the onset comet ping pong much more overt and much more disturbing hub coincidences everyone associated with the business making semiovert semitongueincheek and semisarcastic inferences towards sex with minors the artists that work for and with the business also generate nothing but cultish imagery disembodiment blood beheadings sex and course pizza\n",
      "\n",
      "Removed stop words: 162 words, 1270 characters\n",
      "\n",
      "comet pizza pizza place owned james alefantis former gay boyfriend david brock ceo correct record venue dozens events hillary campaign staff john podesta campaign fundraisers barack obama hillary clinton john’s brother business partner tony podesta birthday party every year httpsislimg1mqphapng it’s also dive according reviews photos hidden bathroom doors creepy murals bathrooms particular murals exclusively nude women well great deal graffiti relating sex reviews restaurant bizarrely polarized websites describing positively note regularly “unsupervised children running around” menu include pedophilic symbol signs decorations neighboring businesses music acts posters promoting acts bizarre presentation content lyrical focus still promoted “for ages” overtly sexual content would suggest otherwise taken place reference videos recorded inside comet ping pong people frequent establishment well referencing comet ping pong positively exterior initially central focus investigation onset comet ping pong much overt much disturbing hub coincidences everyone associated business making semiovert semitongueincheek semisarcastic inferences towards sex minors artists work business also generate nothing cultish imagery disembodiment blood beheadings sex course pizza\n",
      "\n",
      "Removed stop words: 162 words, 1092 characters\n",
      "\n",
      "comet pizza pizza place own jame alefanti former gay boyfriend david brock ceo correct record venu dozen event hillari campaign staff john podesta campaign fundrais barack obama hillari clinton john brother busi partner toni podesta birthday parti everi year httpsislimg1mqphapng it also dive accord review photo hidden bathroom door creepi mural bathroom particular mural exclus nude women well great deal graffiti relat sex review restaur bizarr polar websit describ posit note regular “unsupervis children run around” menu includ pedophil symbol sign decor neighbor busi music act poster promot act bizarr present content lyric focus still promot “for ages” overt sexual content would suggest otherwis taken place refer video record insid comet ping pong peopl frequent establish well referenc comet ping pong posit exterior initi central focus investig onset comet ping pong much overt much disturb hub coincid everyon associ busi make semiovert semitongueincheek semisarcast infer toward sex minor artist work busi also generat noth cultish imageri disembodi blood behead sex cours pizza\n",
      "\n",
      "Lexical Diversity: 0.7962962962962963\n",
      "Punctuation Analysis: 0.0\n",
      "[ 1.]\n",
      "[[ 0.44727217  0.55272783]]\n"
     ]
    }
   ],
   "source": [
    "#SINGLE EXAMPLE\n",
    "\n",
    "print(\"original_text: {0} words, {1} characters\".format(len(pizza_gate_text.split()), len(pizza_gate_text)))\n",
    "print()\n",
    "print(pizza_gate_text)\n",
    "\n",
    "pizza_gate_filtered_text = remove_cap_punc(pizza_gate_text)\n",
    "print()\n",
    "print(\"Removed cap/punc: {0} words, {1} characters\".format(len(pizza_gate_filtered_text.split()), len(pizza_gate_filtered_text)))\n",
    "print()\n",
    "print(pizza_gate_filtered_text)\n",
    "       \n",
    "pizza_gate_filtered_text = remove_overfit_words(pizza_gate_filtered_text, wordlist=wordlist, sourcelist=sourcelist, phraselist=phraselist)\n",
    "print()\n",
    "print(\"Removed overfit words/phrases: {0} words, {1} characters\".format(len(pizza_gate_filtered_text.split()), len(pizza_gate_filtered_text)))\n",
    "print()\n",
    "print(pizza_gate_filtered_text)\n",
    "\n",
    "pizza_gate_filtered_text = remove_shortwords(pizza_gate_filtered_text)\n",
    "print()\n",
    "print(\"Removed short words: {0} words, {1} characters\".format(len(pizza_gate_filtered_text.split()), len(pizza_gate_filtered_text)))\n",
    "print()\n",
    "print(pizza_gate_filtered_text)\n",
    "\n",
    "pizza_gate_filtered_text = remove_stopwords(pizza_gate_filtered_text)\n",
    "pizza_gate_filtered_text = remove_shortwords(pizza_gate_filtered_text)\n",
    "print()\n",
    "print(\"Removed stop words: {0} words, {1} characters\".format(len(pizza_gate_filtered_text.split()), len(pizza_gate_filtered_text)))\n",
    "print()\n",
    "print(pizza_gate_filtered_text)\n",
    "\n",
    "pizza_gate_filtered_text = stem_words(pizza_gate_filtered_text)\n",
    "print()\n",
    "print(\"Removed stop words: {0} words, {1} characters\".format(len(pizza_gate_filtered_text.split()), len(pizza_gate_filtered_text)))\n",
    "print()\n",
    "print(pizza_gate_filtered_text)\n",
    "\n",
    "print()\n",
    "print(\"Lexical Diversity: {}\".format(lexical_diversity(pizza_gate_filtered_text)))\n",
    "print(\"Punctuation Analysis: {}\".format(pct_punct_quesexcl(pizza_gate_text)))\n",
    "\n",
    "print(clf.predict(np.array([lexical_diversity(pizza_gate_filtered_text), pct_punct_quesexcl(pizza_gate_text)]).reshape(1,-1)))\n",
    "print(clf.predict_proba(np.array([lexical_diversity(pizza_gate_filtered_text), pct_punct_quesexcl(pizza_gate_text)]).reshape(1,-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
