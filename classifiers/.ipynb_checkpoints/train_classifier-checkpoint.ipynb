{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cred_fp = '/ebs_volume/data/Credible/'\n",
    "ncred_fp = '/ebs_volume/data/notCredible/'\n",
    "\n",
    "articles = pd.DataFrame(columns=('label',\n",
    "                                 'text',\n",
    "                                 'title',\n",
    "                                 'date',\n",
    "                                 'source'))\n",
    "i = 0    \n",
    "for root, dirs, files in os.walk(cred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print(curr_file)\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    if data[\"source\"] == \"new-york-times\":\n",
    "                        articles.loc[i] = [0,data[\"text\"],data[\"title\"],data[\"date\"],\"the-new-york-times\"]\n",
    "                    else:                        \n",
    "                        articles.loc[i] = [0,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "for root, dirs, files in os.walk(ncred_fp):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\") and 'api' not in file:\n",
    "             curr_file = os.path.join(root, file)\n",
    "             #print(curr_file)\n",
    "             with open(curr_file) as json_file:\n",
    "                try:\n",
    "                    data = json.load(json_file)\n",
    "                    articles.loc[i] = [1,data[\"text\"],data[\"title\"],data[\"date\"],data[\"source\"]]\n",
    "                    i+=1\n",
    "                except ValueError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_cap_punc(in_string):\n",
    "    \"\"\"Function removes capitalization and punctuation from string.\"\"\"\n",
    "    out_string = in_string\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    out_string = out_string.translate(translator)\n",
    "    out_words = out_string.split()\n",
    "    out_words = [word.lower() for word in out_words]\n",
    "    out_string = ' '.join(word for word in out_words)\n",
    "    return(out_string)\n",
    "\n",
    "def remove_overfit_words(in_string, wordlist, sourcelist, phraselist):\n",
    "    \"\"\"Function removes words and phrases indicative of source from string.\n",
    "    This function requires a wordlist of individual words to exclude, a\n",
    "    sourcelist of sources to exclude, and a phraselist of phrases to exclude.\n",
    "    The purpose of this function is to prevent our learner from making undesired\n",
    "    associations between words and phrases that aren't themselves indicative of\n",
    "    a classification beyond their existence in a large proportion of the articles\n",
    "    in our training corpus.\"\"\"\n",
    "    out_string = in_string\n",
    "    for phrase in phraselist:\n",
    "        out_string = out_string.replace(phrase, '')\n",
    "    out_string = out_string.lower()\n",
    "    for source in sourcelist:\n",
    "        out_string = out_string.replace(source, '')\n",
    "    non_url_words = [word for word in out_string.split() if (\"www\" not in word) and (\"https\" not in word)] #remove URLs\n",
    "    out_words = [word for word in non_url_words if word not in wordlist]\n",
    "    out_string = ' '.join(word for word in out_words)\n",
    "    return(out_string)\n",
    "\n",
    "def remove_shortwords(in_string):\n",
    "    \"\"\"Function removes words with length <=2 from string.\"\"\"\n",
    "    out_string = in_string\n",
    "    out_words = out_string.split()\n",
    "    out_words = [word for word in out_words if len(word) > 2]\n",
    "    out_string = ' '.join(word for word in out_words)\n",
    "    return(out_string)\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Function accepts a string and returns a list of the sentences inside it.\"\"\"\n",
    "    caps = \"([A-Z])\"\n",
    "    prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "    suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "    starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "    acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "    websites = \"[.](com|net|org|io|gov)\"\n",
    "    \n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return(sentences)\n",
    "\n",
    "def sent_analysis(text, uoa=\"sentences\"):\n",
    "    \"\"\"If uoa=\"sentences\", function accepts a string with multiple sentences and\n",
    "    returns the average sentiment score for all sentences. If uoa=\"string\",\n",
    "    function returns the overall sentiment score for the string.\"\"\"\n",
    "    if uoa == \"sentences\":\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        counter=0\n",
    "        total_compound=0\n",
    "        for sentence in text:\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            total_compound = total_compound + ss['compound']\n",
    "            counter+=1\n",
    "\n",
    "        if counter==0:\n",
    "            avg_compound=0\n",
    "        else:\n",
    "            avg_compound = total_compound/counter\n",
    "\n",
    "        return(avg_compound)\n",
    "    \n",
    "    elif uoa == \"string\":\n",
    "        filtered_text = remove_cap_punc(text)\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        ss = sid.polarity_scores(filtered_text)\n",
    "        compound = ss['compound']\n",
    "        return(compound)\n",
    "    else:\n",
    "        print(\"uoa (unit of analysis) not recognized\")\n",
    "        \n",
    "def pct_char_quesexcl(title):\n",
    "    \"\"\"Function accepts a string and returns the % of characters that are question\n",
    "    marks or exclamation points.\"\"\"\n",
    "    try:\n",
    "        ques_excl = [char for char in title if char=='?' or char=='!']\n",
    "        return(len(ques_excl)/len(title))\n",
    "    except:\n",
    "        return(0)        \n",
    "\n",
    "def pct_punct_quesexcl(in_string):\n",
    "    \"\"\"Function accepts a string and returns the % of punctuation in it that are \n",
    "    question marks or exclamation points.\"\"\"\n",
    "    try:\n",
    "        punct = [char for char in in_string if char in string.punctuation]\n",
    "        ques_excl = [p for p in punct if p=='?' or p=='!']\n",
    "        return(len(ques_excl)/len(punct))\n",
    "    except:\n",
    "        return(0)\n",
    "    \n",
    "def pct_allcaps(title):\n",
    "    try:\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        title = title.translate(translator)\n",
    "        words = title.split()\n",
    "        all_caps = [word for word in words if word.isupper()]\n",
    "        return(len(all_caps)/len(words))\n",
    "    except:\n",
    "        return(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_articles = articles.drop_duplicates(subset = 'text') #remove duplicates\n",
    "unique_articles = unique_articles[unique_articles[\"text\"].str.len()>200] #remove really short articles\n",
    "\n",
    "#cred_articles = unique_articles[unique_articles[\"label\"]==0.0]\n",
    "cred_articles = unique_articles[unique_articles[\"source\"].isin([\"new-york-times\",\"the-new-york-times\",\"reuters\",\"the-wall-street-journal\",\"the-washington-post\",\"usa-today\"])]\n",
    "#noncred_articles = unique_articles[unique_articles[\"label\"]==1.0]\n",
    "noncred_articles = unique_articles[unique_articles[\"source\"].isin([\"activistpost\",\"dcclothesline\",\"gopthedailydose\",\"infostormer\",\"rickwells\",\"success-street\",\"usanewsflash\",\"usapoliticsnow\",\"usasupreme\"])]\n",
    "\n",
    "cred_articles = cred_articles[~cred_articles[\"date\"].isin(list(set(cred_articles[\"date\"]) - set(noncred_articles[\"date\"])))]\n",
    "date_cnts = Counter(cred_articles[\"date\"])\n",
    "noncred_even = pd.DataFrame(columns=('label','text','title','date','source'))\n",
    "\n",
    "#Ensure an even distribution of publish dates in training set\n",
    "for date in date_cnts:\n",
    "    noncred_even = pd.concat([noncred_even, noncred_articles[noncred_articles[\"date\"]==date].sample(n=date_cnts[date])])\n",
    "    \n",
    "even_articles = pd.concat([cred_articles, noncred_even]) #train set should contain even number of cred/noncred articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load in list of overfit words & phrases from training sources\n",
    "wordlist = [\"advertisement\", \"skip\", \"main\", \"photo\", \"embed\", \"www\", \"com\",\n",
    "            \"https\", \"http\", \"photo\", \"getty\", \"continue\", \"sunday\", \"monday\",\n",
    "            \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"stopthetakeover\"\n",
    "            \"sidebar\", \"usatwentyfour\"]\n",
    "\n",
    "#Generate sources list\n",
    "sources = list(set(even_articles['source']))\n",
    "sourcelist = [source.replace('-', ' ') for source in sources]\n",
    "sourcelist.extend(['rickrwells', 'rickwells', 'rick wells', 'wall street journal', 'gop the daily dose', 'new york times', 'washington post', 'activist post', 'wsj'])\n",
    "\n",
    "\n",
    "#Generate indicative phrase list from training sources\n",
    "phraselist = [\"Share this:\",\n",
    "              \"by usapoliticsnow admin\",\n",
    "              \"Our Standards: The Thomson Reuters Trust Principles\",\n",
    "              \"Don't forget to follow the D.C. Clothesline on Facebook and Twitter. PLEASE help spread the word by sharing our articles on your favorite social networks.\",\n",
    "              \"Share With Your Friends On Facebook, Twitter, Everywhere\",\n",
    "              \"Thank you for reading and sharing my work –  Please look for me, Rick Wells, at http://www.facebook.com/RickRWells/ , http://www.gab.ai/RickRWells , https://plus.google.com/u/0/+RickwellsUs and on my website http://RickWells.US  – Please SUBSCRIBE in the right sidebar at RickWells.US – not dot com.  I’m also at Stop The Takeover, https://www.facebook.com/StopTheTakeover/ and please follow me on Twitter @RickRWells. Subscribe also on my YouTube Channel.\",\n",
    "              \"Like this Article? Share it!\",\n",
    "              \"Do you have information the public should know? Here are some ways you can securely send information and documents to Post journalists.\",\n",
    "              \"Share news tips with us confidentially\",\n",
    "              \"Share on Facebook\",\n",
    "              \"Tweet on Twitter\",\n",
    "              \"We encourage you to share and republish our reports, analyses, breaking news and videos (Click for details).\",\n",
    "              \"Next post\",\n",
    "              \"Previous post\",\n",
    "              \"Thank you for reading and sharing my work – Facebook is trying to starve us out of existence, having cut literally 98% of our traffic over the last year. Your shares are crucial for our survival, and we thank you. We’ve also created a presence on Gab.ai and MeWe.com, although their reach is presently much smaller, the continued abuse by Facebook of conservative voices leaves us no option. We’re remaining on Facebook for the time being, as we make the transition. Please take a look when you have a chance or if we “suddenly disappear” from Facebook as has happened to many other truth-tellers. They’ll either starve us out or take us down, one way or another, sooner or later. Now and in the future, please look for me, Rick Wells, at http://www.facebook.com/RickRWells/ , http://www.gab.ai/RickRWells , https://mewe.com/profile/rick.wells.1 and on my website http://RickWells.US – Please SUBSCRIBE in the right sidebar at RickWells.US – not dot com. I’m also at Stop The Takeover, https://www.facebook.com/StopTheTakeover/ and please follow me on Twitter @RickRWells.\"]\n",
    "\n",
    "even_articles['filtered_text'] = even_articles.apply(lambda x: remove_overfit_words(x['text'], wordlist=wordlist, sourcelist=sourcelist, phraselist=phraselist), axis=1)\n",
    "even_articles['filtered_text'] = even_articles['filtered_text'].apply(remove_shortwords)\n",
    "\n",
    "even_articles['sentences'] = even_articles['text'].apply(split_into_sentences)\n",
    "even_articles['text_sentiment'] = even_articles['sentences'].apply(sent_analysis)\n",
    "even_articles['title_sentiment'] = even_articles.apply(lambda x: sent_analysis(x['title'], uoa=\"string\"), axis=1)\n",
    "even_articles['pct_char_quesexcl_title'] = even_articles['title'].apply(pct_char_quesexcl)\n",
    "even_articles['pct_punc_quesexcl_text'] = even_articles['text'].apply(pct_punct_quesexcl)\n",
    "even_articles['pct_allcaps_title'] = even_articles['title'].apply(pct_allcaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb_clf = Pipeline(steps = [('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df=0, lowercase=True, stop_words='english')),\n",
    "                            ('clf', MultinomialNB())])\n",
    "\n",
    "mnb_scores=[]\n",
    "xgb_scores=[]\n",
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_index, test_index in k_fold.split(even_articles):\n",
    "    train_text = even_articles.iloc[train_index]['filtered_text'].values\n",
    "    train_x = np.array([even_articles.iloc[train_index]['pct_allcaps_title'].values,\n",
    "                        even_articles.iloc[train_index]['pct_punc_quesexcl_text'].values,\n",
    "                        even_articles.iloc[train_index]['pct_char_quesexcl_title'].values,\n",
    "                        even_articles.iloc[train_index]['text_sentiment'].values,\n",
    "                        even_articles.iloc[train_index]['title_sentiment'].values])\n",
    "    train_y = even_articles.iloc[train_index]['label'].values\n",
    "  \n",
    "    test_text = even_articles.iloc[test_index]['filtered_text'].values\n",
    "    test_counts = count_vect.transform(test_text)\n",
    "    test_tfidf = tfidf.transform(test_counts)\n",
    "    test_x = np.array([even_articles.iloc[test_index]['pct_allcaps_title'].values,\n",
    "                       even_articles.iloc[test_index]['pct_punc_quesexcl_text'].values,\n",
    "                       even_articles.iloc[test_index]['pct_char_quesexcl_title'].values,\n",
    "                       even_articles.iloc[test_index]['text_sentiment'].values,\n",
    "                       even_articles.iloc[test_index]['title_sentiment'].values])\n",
    "    test_y = even_articles.iloc[test_index]['label'].values\n",
    "    \n",
    "    #MNB CLASSIFIER\n",
    "    mnb_clf.fit(train_text, train_y)\n",
    "    mnb_predictions = mnb_clf.predict(test_text)\n",
    "    mnb_score = accuracy_score(test_y, mnb_predictions)\n",
    "    mnb_scores.append(mnb_score)\n",
    "    \n",
    "    #XGBOOST\n",
    "    xgb_clf = XGBClassifier(max_depth=3, n_estimators=100).fit(train_x.T, train_y)\n",
    "    xgb_predictions = xgb_clf.predict(test_x.T)\n",
    "    xgb_score = accuracy_score(test_y, xgb_predictions)\n",
    "    xgb_scores.append(xgb_score)\n",
    "\n",
    "perform_statistics = {}\n",
    "    \n",
    "#Calculate classification accuracy for ensemble weighting    \n",
    "perform_statistics['mnb_accuracy'] = sum(mnb_scores)/len(mnb_scores)\n",
    "perform_statistics['xgb_accuracy'] = sum(xgb_scores)/len(xgb_scores)\n",
    "\n",
    "#Calculate mean scores for cred vs. noncred \"tonal\" features to assist with interpreting the model's decisions\n",
    "perform_statistics['mean_sent_score_text_cred'] = np.mean(even_articles['text_sentiment'][even_articles['label']==0])\n",
    "perform_statistics['mean_sent_score_text_noncred'] = np.mean(even_articles['text_sentiment'][even_articles['label']==1])\n",
    "perform_statistics['mean_sent_score_title_cred'] = np.mean(even_articles['title_sentiment'][even_articles['label']==0])\n",
    "perform_statistics['mean_sent_score_title_noncred'] = np.mean(even_articles['title_sentiment'][even_articles['label']==1])\n",
    "perform_statistics['mean_pct_punc_text_cred'] = np.mean(even_articles['pct_punc_quesexcl_text'][even_articles['label']==0])\n",
    "perform_statistics['mean_pct_punc_text_noncred'] = np.mean(even_articles['pct_punc_quesexcl_text'][even_articles['label']==1])\n",
    "perform_statistics['mean_pct_punc_title_cred'] = np.mean(even_articles['pct_char_quesexcl_title'][even_articles['label']==0])\n",
    "perform_statistics['mean_pct_punc_title_noncred'] = np.mean(even_articles['pct_char_quesexcl_title'][even_articles['label']==1])\n",
    "perform_statistics['mean_pct_allcaps_title_cred'] = np.mean(even_articles['pct_allcaps_title'][even_articles['label']==0])\n",
    "perform_statistics['mean_pct_allcaps_title_noncred'] = np.mean(even_articles['pct_allcaps_title'][even_articles['label']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = np.array([even_articles['pct_allcaps_title'].values,\n",
    "                    even_articles['pct_punc_quesexcl_text'].values,\n",
    "                    even_articles['pct_char_quesexcl_title'].values,\n",
    "                    even_articles['text_sentiment'].values,\n",
    "                    even_articles['title_sentiment'].values])\n",
    "train_y = even_articles['label'].values\n",
    "\n",
    "mnb_clf = mnb_clf.fit(even_articles['filtered_text'], train_y)\n",
    "xgb_clf = XGBClassifier(max_depth=3, n_estimators=100).fit(train_x.T, train_y)\n",
    "\n",
    "joblib.dump(mnb_clf, 'mnb_clf.pkl')\n",
    "joblib.dump(xgb_clf, 'xgb_clf.pkl')\n",
    "\n",
    "with open('DONOTDELETE.json', 'w') as outfile:\n",
    "    json.dump(perform_statistics, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import schedule\n",
    "import datetime\n",
    "import newspaper\n",
    "import time\n",
    "\n",
    "def extract_article(url):\n",
    "    \"\"\"Function that takes the url string of a news article and returns the\n",
    "    title and text of the article as a Python dictionary. Built on top of\n",
    "    Newspaper's article scraping & curation library.\"\"\"\n",
    "    link = newspaper.Article(url)\n",
    "    link.download()\n",
    "    link.parse()\n",
    "\n",
    "    article = {}\n",
    "    article[\"title\"] = link.title\n",
    "    article[\"text\"] = link.text\n",
    "\n",
    "    return(article)\n",
    "\n",
    "def create_article(title, text):\n",
    "    \"\"\"Function that produces a Python dictionary containing manually-inputted\n",
    "    title and text.\"\"\"\n",
    "    article = {}\n",
    "    article[\"title\"] = title\n",
    "    article[\"text\"] = text\n",
    "    \n",
    "    return(article)\n",
    "\n",
    "def most_predictive_feats(filtered_text, label, n=10):\n",
    "    \"\"\"Function returns most predictive words (by differential log_prob) in \n",
    "    filtered_text in support of a \"Credible\" or \"Non-Credible\" labeling. n \n",
    "    can be set to adjust the number of words returned.\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    features[\"word\"] = mnb_clf.named_steps['tfidf'].get_feature_names()\n",
    "    features[\"tfidf\"] = list(mnb_clf.named_steps['tfidf'].transform([filtered_text]).toarray()[0])\n",
    "    features[\"log_prob_0\"] = mnb_clf.named_steps['clf'].feature_log_prob_[0]\n",
    "    features[\"log_prob_1\"] = mnb_clf.named_steps['clf'].feature_log_prob_[1]\n",
    "    labels = []\n",
    "    for lp0, lp1 in zip(features[\"log_prob_0\"], features[\"log_prob_1\"]):\n",
    "        if lp1 > lp0:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    features[\"label\"] = labels\n",
    "    features[\"log_prob_diff\"] = abs(features[\"log_prob_1\"] - features[\"log_prob_0\"])\n",
    "    features[\"weighted_log_prob_diff\"] = features[\"tfidf\"] * features[\"log_prob_diff\"]\n",
    "    features_c_sort = features[features[\"label\"]==0].sort_values(by=[\"weighted_log_prob_diff\"], ascending=False)\n",
    "    features_nc_sort = features[features[\"label\"]==1].sort_values(by=[\"weighted_log_prob_diff\"], ascending=False)\n",
    "    if label == \"Non-Credible\":\n",
    "        word_features = list(features_nc_sort[\"word\"].head(n))\n",
    "    elif label == \"Credible\":\n",
    "        word_features = list(features_c_sort[\"word\"].head(n))\n",
    "        \n",
    "    return(word_features)\n",
    "\n",
    "def classify_article(article):\n",
    "    article['filtered_text'] = remove_shortwords(article['text'])\n",
    "    article['sentences'] = split_into_sentences(article['text'])\n",
    "    article['text_sentiment'] = sent_analysis(article['sentences'])\n",
    "    article['title_sentiment'] = sent_analysis(article['title'], uoa=\"string\")\n",
    "    article['pct_char_quesexcl_title'] = pct_char_quesexcl(article['title'])\n",
    "    article['pct_punc_quesexcl_text'] = pct_punct_quesexcl(article['text'])\n",
    "    article['pct_allcaps_title'] = pct_allcaps(article['title'])\n",
    "    \n",
    "    mnb_clf = joblib.load('mnb_clf.pkl')\n",
    "    xgb_clf = joblib.load('xgb_clf.pkl')\n",
    "    \n",
    "    with open('DONOTDELETE.json') as json_data:\n",
    "        perform_statistics = json.load(json_data)\n",
    "\n",
    "    xgb_feats = [article['pct_allcaps_title'],\n",
    "                 article['pct_punc_quesexcl_text'],\n",
    "                 article['pct_char_quesexcl_title'],\n",
    "                 article['text_sentiment'],\n",
    "                 article['title_sentiment']]\n",
    "    \n",
    "    mnb_prob = mnb_clf.predict_proba([article['filtered_text']])\n",
    "    xgb_prob = xgb_clf.predict_proba(xgb_feats)\n",
    "    \n",
    "    classification = {}\n",
    "    classification[\"label_prob\"] = [(((perform_statistics['mnb_accuracy']*mnb_prob[0][0])+(perform_statistics['xgb_accuracy']*xgb_prob[0][0]))/(perform_statistics['mnb_accuracy']+perform_statistics['xgb_accuracy'])), (((perform_statistics['mnb_accuracy']*mnb_prob[0][1])+(perform_statistics['xgb_accuracy']*xgb_prob[0][1]))/(perform_statistics['mnb_accuracy']+perform_statistics['xgb_accuracy']))]\n",
    "    if classification[\"label_prob\"][1] > classification[\"label_prob\"][0]:\n",
    "        classification[\"label\"] = \"Non-Credible\"\n",
    "    else:\n",
    "        classification[\"label\"] = \"Credible\"\n",
    "            \n",
    "    interpretation = {}\n",
    "    interpretation[\"word_feats\"] = most_predictive_feats(article[\"filtered_text\"], classification[\"label\"], n=10)\n",
    "    tone_feats = {}\n",
    "    \n",
    "    tone_feat_classifications = []\n",
    "    if abs(article['pct_allcaps_title'] - perform_statistics['mean_pct_allcaps_title_noncred']) < abs(article['pct_allcaps_title'] - perform_statistics['mean_pct_allcaps_title_cred']):\n",
    "        tone_feat_classifications.append(1)\n",
    "    else:\n",
    "        tone_feat_classifications.append(0)\n",
    "    \n",
    "    if abs(article['pct_punc_quesexcl_text'] - perform_statistics['mean_pct_punc_text_noncred']) < abs(article['pct_punc_quesexcl_text'] - perform_statistics['mean_pct_punc_text_cred']):\n",
    "        tone_feat_classifications.append(1)\n",
    "    else:\n",
    "        tone_feat_classifications.append(0)\n",
    "    \n",
    "    if abs(article['pct_char_quesexcl_title'] - perform_statistics['mean_pct_punc_title_noncred']) < abs(article['pct_char_quesexcl_title'] - perform_statistics['mean_pct_punc_title_cred']):\n",
    "        tone_feat_classifications.append(1)\n",
    "    else:\n",
    "        tone_feat_classifications.append(0)\n",
    "        \n",
    "    if abs(article['text_sentiment'] - perform_statistics['mean_sent_score_text_noncred']) < abs(article['text_sentiment'] - perform_statistics['mean_sent_score_text_cred']):\n",
    "        tone_feat_classifications.append(1)\n",
    "    else:\n",
    "        tone_feat_classifications.append(0)\n",
    "        \n",
    "    if abs(article['title_sentiment'] - perform_statistics['mean_sent_score_title_noncred']) < abs(article['title_sentiment'] - perform_statistics['mean_sent_score_title_cred']):\n",
    "        tone_feat_classifications.append(1)\n",
    "    else:\n",
    "        tone_feat_classifications.append(0)\n",
    "        \n",
    "    if (tone_feat_classifications[0]*xgb_clf.feature_importances_[0] + tone_feat_classifications[1]*xgb_clf.feature_importances_[1] + tone_feat_classifications[2]*xgb_clf.feature_importances_[2])/( xgb_clf.feature_importances_[0] + xgb_clf.feature_importances_[1] + xgb_clf.feature_importances_[2]) > 0.5:\n",
    "        convention_pred = \"Non-Credible\"\n",
    "    else:\n",
    "        convention_pred = \"Credible\"\n",
    "        \n",
    "    if (tone_feat_classifications[3]*xgb_clf.feature_importances_[3] + tone_feat_classifications[4]*xgb_clf.feature_importances_[4])/( xgb_clf.feature_importances_[3] + xgb_clf.feature_importances_[4]) > 0.5:\n",
    "        sentiment_pred = \"Non-Credible\"\n",
    "    else:\n",
    "        sentiment_pred = \"Credible\"\n",
    "    \n",
    "    if convention_pred == classification[\"label\"]:\n",
    "        tone_feats[\"convention\"] = convention_pred\n",
    "        \n",
    "    if sentiment_pred == classification[\"label\"]:\n",
    "        tone_feats[\"sentiment\"] = sentiment_pred\n",
    "    \n",
    "    interpretation[\"tone_feats\"] = tone_feats\n",
    "   \n",
    "    classification[\"interpretation\"] = interpretation\n",
    "        \n",
    "    return(classification)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interpretation': {'tone_feats': {'sentiment': 'Non-Credible'},\n",
       "  'word_feats': ['isis',\n",
       "   'cia',\n",
       "   'article',\n",
       "   'com',\n",
       "   'claiming',\n",
       "   'fact',\n",
       "   'sources',\n",
       "   'crazy',\n",
       "   'expose',\n",
       "   'journalist']},\n",
       " 'label': 'Non-Credible',\n",
       " 'label_prob': [0.39106843531637203, 0.60893156468362941]}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_article(extract_article(\"https://www.infowars.com/top-ten-reasons-to-doubt-official-story-on-assad-poison-gas-attack/\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
